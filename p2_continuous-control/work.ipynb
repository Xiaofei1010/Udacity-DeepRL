{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><b><font size=10> CONTINUOUS CONTROL</font></b>\n",
    "#### <i>...implementation for Udacity Deep Reinforcement Learning \n",
    "<hr><hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Imports for the notebook\n",
    "This Notebook uses code from separate python files where most of the implementation is handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import environment as E\n",
    "from buffers import ReplayBuffer, nStepBuffer\n",
    "from agent import D4PG_Agent\n",
    "\n",
    "#from get_args import get_args\n",
    "\n",
    "import os.path\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "import importlib\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from unityagents import UnityEnvironment\n",
    "from collections import deque\n",
    "import torchvision.transforms as T\n",
    "import multiprocessing as multi\n",
    "multi.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually declare an ARGS class\n",
    "<i> For testing code in the notebook, to take the place of argparser in the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.train = True\n",
    "        self.nographics = False\n",
    "        self.num_eps = 10\n",
    "        self.rollout = 5\n",
    "        self.batchsize = 64\n",
    "        self.pretrain = 1000\n",
    "        \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Confirm that the args are all set the way we want them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: True\n",
      "NOGRAPHICS: False\n",
      "NUM_EPS: 10\n",
      "ROLLOUT: 5\n",
      "BATCHSIZE: 64\n",
      "PRETRAIN: 1000\n"
     ]
    }
   ],
   "source": [
    "for arg in vars(args):\n",
    "    if arg == \"sep\": continue\n",
    "    print(\"{}: {}\".format(arg.upper(), getattr(args, arg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the environment\n",
    "<i> & print a bit of information contained in the wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 33\n",
      "Action size: 4\n",
      "Num Agents: 20\n"
     ]
    }
   ],
   "source": [
    "env = E.Environment(args)\n",
    "print(\"State size:\", env.state_size)\n",
    "print(\"Action size:\", env.action_size)\n",
    "print(\"Num Agents:\", env.agent_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Test code as it's developed\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take random actions in the environment below \n",
    "<i>\n",
    "-to check that code is working<br>\n",
    "-to get familiar with the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.train = False\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.020499999541789292\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "scores = np.zeros(env.agent_count)\n",
    "states = env.states\n",
    "actions = np.zeros((20,4))\n",
    "for i in range(100):\n",
    "    #actions = np.random.randn(env.agent_count, env.action_size)\n",
    "    actions[:,3] += .01\n",
    "    actions = np.clip(actions, -1, 1)\n",
    "    next_states, rewards, dones = env.step(actions)\n",
    "    scores += rewards\n",
    "    states = next_states\n",
    "    if np.any(dones):\n",
    "        break\n",
    "    i += 1\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]]\n",
      "[[0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]]\n",
      "[[0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]]\n",
      "[[0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]]\n",
      "[[0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]]\n",
      "[[0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]]\n",
      "[[0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]]\n",
      "[[0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]]\n",
      "[[0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]]\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "actions = np.zeros((20,4))\n",
    "for i in range(10):\n",
    "    actions[:,0] += .1\n",
    "    print(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force-reload modules as they're updated\n",
    "<i> This notebook was developed as the code is written in Atom, the below cell reloads the modules as they're needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent\n",
    "importlib.reload(agent)\n",
    "#importlib.reload(E)\n",
    "importlib.reload(models)\n",
    "from agent import D4PG_Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d4pg_agent = D4PG_Agent(env.state_size, env.action_size, env.agent_count)\n",
    "# print(d4pg_agent.__class__.__name__)\n",
    "# print(d4pg_agent.memory)\n",
    "# agent.initialize_memory(10, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "states = env.states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out Actor actions without training\n",
    "<i> Test the <b>Actor</b> network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIONS: [ 0.12072824 -0.08650129 -0.2426841   0.20263317]\n",
      "ACTIONS: [ 0.11929604  0.0774109   0.15026315 -0.14079183]\n",
      "ACTIONS: [-0.21552052  0.3036239  -0.05686849  0.16493551]\n",
      "ACTIONS: [-0.37239876  0.64675504 -0.02954452 -0.41759738]\n",
      "ACTIONS: [-0.40439492  0.49016446 -0.09638876  0.5759712 ]\n",
      "ACTIONS: [ 0.18600334 -0.13982823 -0.18315789 -0.1067877 ]\n",
      "ACTIONS: [ 0.10396563  0.20145947 -0.04876871  0.49385545]\n",
      "ACTIONS: [-0.18973796 -0.23842593 -0.01363463  0.26116577]\n",
      "ACTIONS: [ 0.12457623 -0.04857243  0.06835352 -0.2388278 ]\n",
      "ACTIONS: [-0.08805268 -0.5120842  -0.18368335 -0.21154818]\n",
      "ACTIONS: [ 0.22746587  0.29810438 -0.20771603 -0.5380932 ]\n",
      "ACTIONS: [ 0.32480836  0.5606363   0.04752121 -0.37489942]\n",
      "ACTIONS: [ 0.25482413 -0.12632596  0.11426903 -0.23253416]\n",
      "ACTIONS: [-0.04591284 -0.48473155 -0.12828822 -0.40005875]\n",
      "ACTIONS: [-0.12775998  0.27066866 -0.02793056  0.14100502]\n",
      "ACTIONS: [ 0.0389617  -0.6315945   0.14557207 -0.23061852]\n",
      "ACTIONS: [-0.28976026 -0.40605357  0.5128111   0.3156206 ]\n",
      "ACTIONS: [ 0.04737271 -0.36484262 -0.47021213 -0.02187341]\n",
      "ACTIONS: [-0.4216092   0.15118648  0.03128338  0.11589441]\n",
      "ACTIONS: [ 0.01606118  0.5234255   0.28901285 -0.21220809]\n",
      "ACTIONS: [ 0.5250722  -0.16561697 -0.14654218  0.08694129]\n",
      "ACTIONS: [ 0.36524877 -0.00681528  0.25105527  0.06142449]\n",
      "ACTIONS: [ 0.48513132  0.2382872  -0.17689939  0.31031933]\n",
      "ACTIONS: [ 0.30648738  0.02770824 -0.17873181  0.04762455]\n",
      "ACTIONS: [-0.32926205 -0.3709646   0.20545831  0.08505697]\n",
      "ACTIONS: [ 0.06693208 -0.36707902  0.07644779  0.1119006 ]\n",
      "ACTIONS: [-1.         -0.04741302 -0.38507655 -0.03725885]\n",
      "ACTIONS: [ 0.22106649 -0.14138192  0.23810844 -0.2906935 ]\n",
      "ACTIONS: [ 0.22334993  0.29404452 -0.04155547 -0.14612043]\n",
      "ACTIONS: [-0.31963554 -0.4461267  -0.30007142 -0.00615189]\n",
      "ACTIONS: [-0.13366449 -0.2226991   0.3303915  -0.27068284]\n",
      "ACTIONS: [-0.04415014 -0.14551754 -0.32131237  0.27187738]\n",
      "ACTIONS: [ 0.4342598  -0.38873953 -0.38753417 -0.27253994]\n",
      "ACTIONS: [ 0.18032834  0.07462768  0.12816897 -0.0629931 ]\n",
      "ACTIONS: [ 0.71270835  0.16240747 -0.01864175 -0.21183746]\n",
      "ACTIONS: [-0.27315181 -0.20842376  0.15113765  0.13595015]\n",
      "ACTIONS: [ 0.01791976  0.05756683  0.20016502 -0.11446424]\n",
      "ACTIONS: [-0.12851964  0.5347632  -0.23530322 -0.34535116]\n",
      "ACTIONS: [0.13821794 0.5174551  0.26053464 0.09365007]\n",
      "ACTIONS: [ 0.15876238  0.503019   -0.02432686  0.00557923]\n",
      "ACTIONS: [-0.01297571  0.5648322  -0.09095738  0.0629812 ]\n",
      "ACTIONS: [-0.06447558 -0.23799656 -0.2852183   0.07028619]\n",
      "ACTIONS: [-0.43395257  0.0452313   0.17833775  0.20840147]\n",
      "ACTIONS: [ 0.05967616  0.0849917   0.31457388 -0.09193315]\n",
      "ACTIONS: [ 0.13781719 -0.50812846 -0.40135875 -0.40875077]\n",
      "ACTIONS: [-0.22618903 -0.06824914 -0.16521227  0.4225027 ]\n",
      "ACTIONS: [ 0.21166241  0.70958567 -0.07557392 -0.5496078 ]\n",
      "ACTIONS: [ 0.3458147   0.31176662  0.34754732 -0.4983181 ]\n",
      "ACTIONS: [-0.769729    0.2888823   0.32268023  0.56703484]\n",
      "ACTIONS: [ 0.42391065 -0.08311993  0.39025408 -0.06502116]\n",
      "ACTIONS: [ 0.27962738  0.14263286 -0.06177215  0.08429126]\n",
      "ACTIONS: [ 0.29337782 -0.3576529   0.13087739  0.12513973]\n",
      "ACTIONS: [ 0.04873787 -0.26305985 -0.05451235 -0.5353533 ]\n",
      "ACTIONS: [-0.33282256  0.3198431  -0.17298396  0.45262343]\n",
      "ACTIONS: [ 0.5679735  -0.48414248 -0.57126415  0.3291875 ]\n",
      "ACTIONS: [-0.22942573 -0.15944242  0.12428928  0.2580234 ]\n",
      "ACTIONS: [ 0.10955698  0.03991408  0.1873713  -0.45172465]\n",
      "ACTIONS: [ 0.35275027  0.00641204 -0.19885124 -0.71200144]\n",
      "ACTIONS: [-0.07790359  0.42106625 -0.06504136 -0.59945023]\n",
      "ACTIONS: [-0.01903492  0.1502231   0.04516786  0.2645027 ]\n",
      "ACTIONS: [-0.04208948 -0.23583068 -0.3027693   0.02875751]\n",
      "ACTIONS: [ 0.11839127 -0.35526547 -0.08245274  0.24794929]\n",
      "ACTIONS: [-0.6800787  -0.48854655  0.4927831   0.32590875]\n",
      "ACTIONS: [-0.25366595  0.06205123 -0.3411436   0.19157307]\n",
      "ACTIONS: [ 0.09181947 -0.04342423  0.20018746 -0.09486665]\n",
      "ACTIONS: [-0.2673768  -0.22917771  0.01782488 -0.22003579]\n",
      "ACTIONS: [-0.00962315 -0.54040384 -0.0297155   0.6061525 ]\n",
      "ACTIONS: [ 0.40903232 -0.06678997  0.17330432  0.30477387]\n",
      "ACTIONS: [ 0.319052    0.20521122 -0.14733939 -0.5790094 ]\n",
      "ACTIONS: [ 0.04184839 -0.3890094   0.315954   -0.05233695]\n",
      "ACTIONS: [-0.20236386 -0.03345454  0.12621924 -0.41441184]\n",
      "ACTIONS: [ 0.09802423  0.08833572 -0.15400536  0.13180089]\n",
      "ACTIONS: [ 0.38873604 -0.5156309  -0.1521238   0.3640067 ]\n",
      "ACTIONS: [ 0.36035475 -0.5414669  -0.4999062  -0.3080816 ]\n",
      "ACTIONS: [ 0.56373376 -0.19451483 -0.03451609  0.28301698]\n",
      "ACTIONS: [0.05561407 0.19755049 0.17129329 0.34235597]\n",
      "ACTIONS: [ 0.5278799   0.28653768  0.26260802 -0.05397813]\n",
      "ACTIONS: [0.48767284 0.10613584 0.17681554 0.05513634]\n",
      "ACTIONS: [0.60768133 0.24555601 0.09480144 0.22957668]\n",
      "ACTIONS: [ 0.21570075  0.19259754 -0.13349421  0.02378745]\n",
      "ACTIONS: [0.6193738  0.02655462 0.14264272 0.2613116 ]\n",
      "ACTIONS: [ 0.475745    0.29863054 -0.03646495  0.34418547]\n",
      "ACTIONS: [-0.29618782  0.32685718  0.02951539  0.06365198]\n",
      "ACTIONS: [-0.10052114  0.43530935  0.22925463  0.01088234]\n",
      "ACTIONS: [-0.05444481 -0.17154554  0.1167794   0.7679666 ]\n",
      "ACTIONS: [-0.20350663 -0.44245994 -0.0190886   0.15579931]\n",
      "ACTIONS: [0.29012436 0.16497733 0.3654102  0.39193213]\n",
      "ACTIONS: [ 0.11421129  0.2883962   0.10319533 -0.08114213]\n",
      "ACTIONS: [-0.03122737  0.11826081 -0.50668615  0.57303673]\n",
      "ACTIONS: [ 0.07085722 -0.47440276  0.0561147  -0.39485812]\n",
      "ACTIONS: [ 0.19628245 -0.29043323  0.18617587  0.14708117]\n",
      "ACTIONS: [ 0.16099007  0.5784021  -0.24180616 -0.02190557]\n",
      "ACTIONS: [ 0.37166995 -0.3755601   0.26543388 -0.10323314]\n",
      "ACTIONS: [-0.11478207  0.23697755 -0.28136674 -0.00495759]\n",
      "ACTIONS: [ 0.33916378  0.11421753 -0.3427755   0.8846461 ]\n",
      "ACTIONS: [0.13702801 0.01574574 0.00157456 0.17608286]\n",
      "ACTIONS: [-0.6031077  -0.6891185  -0.02976601  0.28609738]\n",
      "ACTIONS: [ 0.39873162 -0.0701582  -0.35220045  0.07330863]\n",
      "ACTIONS: [-0.05822118  0.13974406 -0.24670288 -0.1098738 ]\n",
      "ACTIONS: [ 0.08690572 -0.9067861   0.24462153  0.02237314]\n",
      "ACTIONS: [ 0.08654582 -0.40093875  0.11793784  0.10525386]\n",
      "ACTIONS: [-0.1677838  -0.31448978 -0.3100038  -0.18537022]\n",
      "ACTIONS: [-0.16769813 -0.13723993 -0.23541653 -0.3561195 ]\n",
      "ACTIONS: [ 0.22812457 -0.27596858  0.4179345   0.76440376]\n",
      "ACTIONS: [ 0.34971756 -0.23992029  0.04224832  0.13222887]\n",
      "ACTIONS: [ 0.18768722 -0.3273243  -0.0463257   0.2441951 ]\n",
      "ACTIONS: [ 0.13990521 -0.37010863 -0.24982257  0.12011455]\n",
      "ACTIONS: [-0.18128483 -0.33034378  0.32490894 -0.35541275]\n",
      "ACTIONS: [ 0.16884814  0.3555302   0.03312385 -0.2616968 ]\n",
      "ACTIONS: [ 0.33884874 -0.0360298  -0.1516967   0.34650853]\n",
      "ACTIONS: [-0.01680483 -0.08175574 -0.0409616   0.2572    ]\n",
      "ACTIONS: [-0.3385696  -0.48538217 -0.0610835  -0.047984  ]\n",
      "ACTIONS: [0.37675494 0.19738682 0.4352237  0.28741178]\n",
      "ACTIONS: [ 0.5641942  -0.6577435  -0.13943557  0.04507483]\n",
      "ACTIONS: [0.19498216 0.24390413 0.11187329 0.27188197]\n",
      "ACTIONS: [ 0.37726358 -0.47100967  0.12335388 -0.12910676]\n",
      "ACTIONS: [-0.27992973 -0.13273963 -0.55539113  0.04554813]\n",
      "ACTIONS: [-0.43711498  0.29843765 -0.3621427  -0.32090107]\n",
      "ACTIONS: [-0.33646095  0.28438497 -0.07166786 -0.1864281 ]\n",
      "ACTIONS: [-0.17079675  0.26686454  0.11652339  0.4309071 ]\n",
      "ACTIONS: [ 0.22706768 -0.2679106  -0.11680066 -0.65070915]\n",
      "ACTIONS: [-0.2618039  -0.34986743  0.04906085  0.40223852]\n",
      "ACTIONS: [ 0.06780311 -0.04629479  0.3597538   0.23808241]\n",
      "ACTIONS: [-0.0307349   0.2965027  -0.09915745  0.00778235]\n",
      "ACTIONS: [-0.06921587 -0.32254666 -0.52644676 -0.18287192]\n",
      "ACTIONS: [ 0.3079257   0.11719385  0.32132795 -0.1868025 ]\n",
      "ACTIONS: [-0.5820961  -0.2208445  -0.21874702 -0.43038008]\n",
      "ACTIONS: [-0.1271359   0.36159697  0.05247606  0.5429327 ]\n",
      "ACTIONS: [ 0.3351504   0.28995764  0.19803412 -0.08786441]\n",
      "ACTIONS: [-0.21349916 -0.27102432  0.37673387 -0.20951855]\n",
      "ACTIONS: [ 0.22203793  0.05026867  0.39089975 -0.3569557 ]\n",
      "ACTIONS: [ 0.23384848 -0.03010467  0.16460328 -0.16859886]\n",
      "ACTIONS: [-0.5558036   0.0395543   0.38841027 -0.2635501 ]\n",
      "ACTIONS: [0.32387164 0.06586589 0.04054075 0.23144428]\n",
      "ACTIONS: [ 0.07308793 -0.41120273  0.587348    0.68347514]\n",
      "ACTIONS: [-0.11869888 -0.11839828 -0.10328354 -0.14059766]\n",
      "ACTIONS: [-0.37004143 -0.2778078   0.17480655 -0.03322445]\n",
      "ACTIONS: [0.39091232 0.05465024 0.1371174  0.18996155]\n",
      "ACTIONS: [ 0.00287282  0.02719186 -0.31679484 -0.05985924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIONS: [-0.19308537 -0.14845064 -0.40432417 -0.4416672 ]\n",
      "ACTIONS: [ 0.1012351  -0.31623068  0.00547595 -0.19404681]\n",
      "ACTIONS: [-0.2970166  -0.18865255 -0.12186845 -0.30413297]\n",
      "ACTIONS: [ 0.40719062 -0.36198708 -0.18326634 -0.30867195]\n",
      "ACTIONS: [-0.23754944 -0.3127232  -0.5600174  -0.10123626]\n",
      "ACTIONS: [-0.3259422  -0.25763902  0.34360456 -0.07229388]\n",
      "ACTIONS: [-0.2848015   0.2072718   0.21084322  0.13098921]\n",
      "ACTIONS: [ 0.5999527  -0.2404937  -0.6527139   0.37243307]\n",
      "ACTIONS: [ 0.29044706  0.03963693 -0.39005908  0.14409314]\n",
      "ACTIONS: [-0.61647457  0.00718306 -0.09980967  0.58261085]\n",
      "ACTIONS: [-0.20516203 -0.07536345  0.01494337  0.08495621]\n",
      "ACTIONS: [-0.01981568  0.17704473 -0.22985974 -0.44495985]\n",
      "ACTIONS: [-0.13787696 -0.21050553 -0.10659299 -0.031178  ]\n",
      "ACTIONS: [ 0.16463126 -0.23933665  0.11565618  0.28922215]\n",
      "ACTIONS: [ 0.07802901 -0.52407855 -0.13504197 -0.5090258 ]\n",
      "ACTIONS: [-0.29265043 -0.42298955 -0.3449492   0.54416215]\n",
      "ACTIONS: [-0.20898987 -0.14429957  0.24299993 -0.60190624]\n",
      "ACTIONS: [-0.03539062  0.14385378 -0.13102512  0.16737087]\n",
      "ACTIONS: [-0.18075672  0.18761957 -0.44548932  0.07738476]\n",
      "ACTIONS: [-0.07916835 -0.06223969  0.4310729   0.1719856 ]\n",
      "ACTIONS: [-0.70851046  0.3597815  -0.00467604  0.27269873]\n",
      "ACTIONS: [ 0.06953944 -0.26298454  0.15012781  0.3764766 ]\n",
      "ACTIONS: [ 0.5456411  -0.85621715 -0.14929447 -0.22546786]\n",
      "ACTIONS: [ 0.05462234 -0.06766194 -0.315823   -0.23484688]\n",
      "ACTIONS: [-0.00341505 -0.07610615 -0.14122036 -0.09580076]\n",
      "ACTIONS: [-0.19149776  0.14341529 -0.25164536  0.41149724]\n",
      "ACTIONS: [-0.26033676  0.21068318 -0.03610243  0.11925326]\n",
      "ACTIONS: [-0.11485713 -0.28350383  0.11431091  0.17168567]\n",
      "ACTIONS: [-0.01236092  0.03446379  0.73869604  0.09306408]\n",
      "ACTIONS: [ 0.15665363 -0.49879032  0.14381604 -0.296399  ]\n",
      "ACTIONS: [0.30222628 0.46053073 0.24858302 0.26563814]\n",
      "ACTIONS: [ 0.46805    -0.13786548 -0.21645243 -0.03406036]\n",
      "ACTIONS: [-0.24179327  0.02470156 -0.44260538 -0.36633068]\n",
      "ACTIONS: [ 0.26998794 -0.5160101  -0.12515736 -0.4378627 ]\n",
      "ACTIONS: [ 0.21976478 -0.08226235  0.3334752  -0.07406174]\n",
      "ACTIONS: [-0.02699632 -0.11213605  0.51103497 -0.00272619]\n",
      "ACTIONS: [ 0.22044796 -0.25558403 -0.18098414 -0.38037035]\n",
      "ACTIONS: [-0.37112865  0.15748496  0.39110506  0.34994742]\n",
      "ACTIONS: [-0.12023014  0.35940868  0.06054145  0.22401576]\n",
      "ACTIONS: [-0.19820657 -0.11397031 -0.29261726 -0.32489926]\n",
      "ACTIONS: [ 0.12558292 -0.6608214  -0.1784902   0.10155964]\n",
      "ACTIONS: [-0.15730001 -0.7480443   0.29907265  0.06752676]\n",
      "ACTIONS: [ 0.19337538 -0.01804016 -0.07225776 -0.0179102 ]\n",
      "ACTIONS: [ 0.09937019  0.4670587  -0.03255556  0.05784579]\n",
      "ACTIONS: [-0.07745738 -0.25085244 -0.03575396  0.11530763]\n",
      "ACTIONS: [-0.33321872 -0.25907204 -0.04239857 -0.17731969]\n",
      "ACTIONS: [ 0.46672752 -0.00807463  0.23462752  0.5667722 ]\n",
      "ACTIONS: [ 0.02854625 -0.19939162 -0.15801562 -0.31146625]\n",
      "ACTIONS: [0.16904308 0.03052315 0.2129804  0.05906524]\n",
      "ACTIONS: [ 0.09682719  0.37468505  0.23068978 -0.46791568]\n",
      "ACTIONS: [-0.20513634  0.02481068 -0.2131604  -0.25667074]\n",
      "ACTIONS: [ 0.03980509 -0.22125496  0.49231791 -0.13599348]\n",
      "ACTIONS: [-0.12223948 -0.03501112 -0.24335991 -0.37323678]\n",
      "ACTIONS: [0.21601062 0.3013227  0.32221714 0.2422848 ]\n",
      "ACTIONS: [ 0.33105302  0.5014165  -0.21920471  0.3030549 ]\n",
      "ACTIONS: [-0.12979455 -0.26682112  0.40005344 -0.04206098]\n",
      "ACTIONS: [ 0.40097502 -0.6536947   0.25569165 -0.03440954]\n",
      "ACTIONS: [ 0.2606492   0.06914192 -0.13295735 -0.22647895]\n",
      "ACTIONS: [-0.16708706  0.10589762 -0.38537347 -0.62062097]\n",
      "ACTIONS: [ 0.24883352 -0.2854471   0.23209336 -0.18220735]\n",
      "ACTIONS: [0.18531752 0.1405809  0.14034995 0.4333684 ]\n",
      "ACTIONS: [ 0.2917533  -0.14844325 -0.03170482  0.33332047]\n",
      "ACTIONS: [-0.29459035 -0.12418007 -0.18309948 -0.5311579 ]\n",
      "ACTIONS: [ 0.25175548  0.11621442 -0.2672519   0.3876999 ]\n",
      "ACTIONS: [0.07039019 0.04305758 0.32508677 0.3939119 ]\n",
      "ACTIONS: [0.3032262  0.06680118 0.17925589 0.4877089 ]\n",
      "ACTIONS: [-0.35186183  0.44549388 -0.5006295  -0.19144003]\n",
      "ACTIONS: [-0.17691745  0.2178276  -0.22990774 -0.01802457]\n",
      "ACTIONS: [-0.2966395   0.48247606 -0.3549839  -0.328011  ]\n",
      "ACTIONS: [-0.2905987  -0.12538728 -0.2688496   0.4409291 ]\n",
      "ACTIONS: [-0.72368515  0.49027938 -0.16328584 -0.54535675]\n",
      "ACTIONS: [-0.10429411 -0.06471924  0.10896499  0.5148811 ]\n",
      "ACTIONS: [ 0.177107    0.16323103 -0.21788675  0.07358457]\n",
      "ACTIONS: [ 0.3288256   0.24308378 -0.21848665 -0.24024883]\n",
      "ACTIONS: [ 0.23202316 -0.10230517  0.01737489  0.08074605]\n",
      "ACTIONS: [-0.10382812  0.17490308  0.25018764  0.19841012]\n",
      "ACTIONS: [ 0.24061166  0.17234486  0.1359535  -0.50931185]\n",
      "ACTIONS: [-0.3568521  -0.33083025 -0.32349452 -0.0144492 ]\n",
      "ACTIONS: [ 0.11041041 -0.15519442 -0.29376608  0.28753585]\n",
      "ACTIONS: [ 0.34362116  0.0881452   0.18840177 -0.23154098]\n",
      "ACTIONS: [-0.28969136  0.37419003 -0.02080509  0.57595336]\n",
      "ACTIONS: [-0.39393175 -0.12422549 -0.52193654 -0.24504676]\n",
      "ACTIONS: [ 0.7691415  -0.04752381  0.09496696  0.20339872]\n",
      "ACTIONS: [ 0.2648017   0.29148263  0.5738116  -0.06491313]\n",
      "ACTIONS: [ 0.4848829   0.4240856   0.41030928 -0.4961044 ]\n",
      "ACTIONS: [-0.42506728 -0.05685405  0.40545344  0.153863  ]\n",
      "ACTIONS: [-0.30838856 -0.05031285  0.08115368  0.11060416]\n",
      "ACTIONS: [-0.11841866  0.2647306   0.01966823 -0.00755777]\n",
      "ACTIONS: [-1.          0.07798137 -0.23270696  0.23380303]\n",
      "ACTIONS: [-0.25743347  0.07651289 -0.40646878  0.26012057]\n",
      "ACTIONS: [ 0.2565387  -0.08507421  0.06316472 -0.01862162]\n",
      "ACTIONS: [ 0.34010756 -0.02002699 -0.32201132 -0.28048554]\n",
      "ACTIONS: [ 0.417269   -0.41584173 -0.02681993  0.20743856]\n",
      "ACTIONS: [ 0.32970756  0.01180344  0.3358895  -0.0408136 ]\n",
      "ACTIONS: [0.27389267 0.45495808 0.02625098 0.16251071]\n",
      "ACTIONS: [ 0.02437342 -0.16253941  0.41739827 -0.17473163]\n",
      "ACTIONS: [ 0.25458488 -0.19911581  0.7386966   0.14540048]\n",
      "ACTIONS: [-0.292565   -0.55793166 -0.3589961   0.20212658]\n",
      "ACTIONS: [-0.1655347  -0.28587732 -0.5751646  -0.20749155]\n",
      "ACTIONS: [ 0.19306733 -0.1906505   0.05902038 -0.47734478]\n",
      "ACTIONS: [ 0.18533686  0.16088808 -0.42014444 -0.44667292]\n",
      "ACTIONS: [-0.11000552 -0.10024352 -0.3210139   0.00115874]\n",
      "ACTIONS: [-0.18216927  0.1183412   0.08858844  0.21637501]\n",
      "ACTIONS: [-0.12018777  0.6861678  -0.13699356 -0.18908237]\n",
      "ACTIONS: [-0.18145882 -0.29234686 -0.2780028   0.30006737]\n",
      "ACTIONS: [ 0.13570596 -0.18393     0.34678483 -0.8767341 ]\n",
      "ACTIONS: [ 0.3640279  -0.56874514 -0.18446313 -0.15567645]\n",
      "ACTIONS: [ 0.06333127  0.01291475  0.07206418 -0.28482047]\n",
      "ACTIONS: [ 0.09364253  0.2062771  -0.20394914 -0.01531293]\n",
      "ACTIONS: [ 0.12384502  0.05940792 -0.28667912  0.16974147]\n",
      "ACTIONS: [ 0.60175574  0.02300851 -0.22141595 -0.04771792]\n",
      "ACTIONS: [-0.06616092  0.5714951   0.30314016  0.23225616]\n",
      "ACTIONS: [-0.15725672 -0.3354298  -0.02482574 -0.02616382]\n",
      "ACTIONS: [ 0.3820557   0.38998136 -0.63307375  0.0205385 ]\n",
      "ACTIONS: [ 0.18143597 -0.18347037  0.08475189  0.3696936 ]\n",
      "ACTIONS: [-0.26607332 -0.6748431   0.3047479  -0.08961377]\n",
      "ACTIONS: [ 0.12189981 -0.05453053 -0.13583697 -0.05163096]\n",
      "ACTIONS: [-0.4106306   0.57907665 -0.11114696  0.29810706]\n",
      "ACTIONS: [ 0.07408591  0.23250693 -0.07407413  0.14955793]\n",
      "ACTIONS: [ 0.11859994  0.39179787 -0.08797172 -0.10443723]\n",
      "ACTIONS: [ 0.11748507  0.10669719 -0.1602456   0.12732063]\n",
      "ACTIONS: [-0.18229407 -0.06415012 -0.46005365  0.2378102 ]\n",
      "ACTIONS: [ 0.22217776 -0.12554829 -0.3998621   0.13608174]\n",
      "ACTIONS: [ 0.2159306   0.24637955 -0.37424675 -0.00317833]\n",
      "ACTIONS: [ 0.10492505 -0.27707827  0.2324786   0.08438898]\n",
      "ACTIONS: [-0.24151616 -0.58672315  0.39074975  0.5116971 ]\n",
      "ACTIONS: [1.         0.11566169 0.00847777 0.6175138 ]\n",
      "ACTIONS: [ 0.25269476 -0.15366513  0.9081753  -0.39581272]\n",
      "ACTIONS: [ 0.15652944 -0.41886795  1.         -0.63887745]\n",
      "ACTIONS: [0.2570316  0.18090563 0.25436354 0.12695673]\n",
      "ACTIONS: [ 0.07679246 -0.22895917  0.43537265 -0.24238251]\n",
      "ACTIONS: [ 0.08576085 -0.13417014  0.21168216 -0.14378081]\n",
      "ACTIONS: [ 0.40097722 -0.22743551  0.02828052 -0.35605195]\n",
      "ACTIONS: [-0.15488712 -0.20815259  0.10037664 -0.23394504]\n",
      "ACTIONS: [-0.17435022  0.34891006  0.5054734   0.30242524]\n",
      "ACTIONS: [ 0.0712414   0.1247784  -0.30516493  0.25967118]\n",
      "ACTIONS: [-0.47596288 -0.11076368 -0.31031045 -0.4531579 ]\n",
      "ACTIONS: [ 0.26235726  0.3209477  -0.1260283  -0.01179141]\n",
      "ACTIONS: [-0.14371033 -0.516758    0.23340505 -0.43010202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIONS: [ 0.01999115 -0.07211079  0.05800765 -0.7156198 ]\n",
      "ACTIONS: [-0.1131888  -0.03167914  0.39704704  0.04985125]\n",
      "ACTIONS: [ 0.1707986   0.17535986 -0.18388934  0.18508905]\n",
      "ACTIONS: [ 0.34602582 -0.5155452  -0.3216077  -0.49399054]\n",
      "ACTIONS: [ 0.21240127  0.220057    0.0998925  -0.05200554]\n",
      "ACTIONS: [-0.42082015  0.5404009   0.3127645   0.32569203]\n",
      "ACTIONS: [-0.01972523  0.5407506   0.16946614 -0.04559203]\n",
      "ACTIONS: [ 0.20376284  0.05253517  0.38212094 -0.17802615]\n",
      "ACTIONS: [-0.49493235  0.14781837  0.41671538 -0.36746293]\n",
      "ACTIONS: [ 0.22824979  0.27843413 -0.5000596  -0.571131  ]\n",
      "ACTIONS: [ 0.40300834  0.18392001  0.27293563 -0.38836813]\n",
      "ACTIONS: [ 0.25405303 -0.16768111 -0.22785416 -0.27156442]\n",
      "ACTIONS: [-0.12524925  0.40104526  0.41193968  0.19621332]\n",
      "ACTIONS: [-0.13101798 -0.2090228   0.11435518 -0.13032082]\n",
      "ACTIONS: [ 0.18751849 -0.17107828  0.28036445  0.40508705]\n",
      "ACTIONS: [-0.38494578 -0.21333385 -0.07074345  0.02364682]\n",
      "ACTIONS: [-0.32675585 -0.18471791 -0.04540517  0.31333143]\n",
      "ACTIONS: [-0.00838305 -0.24503477  0.17986609 -0.10867506]\n",
      "ACTIONS: [-0.14000261 -0.0898219  -0.07378695  0.12377168]\n",
      "ACTIONS: [0.24421233 0.7300248  0.02961016 0.38967097]\n",
      "ACTIONS: [ 0.01267026 -0.04570791  0.00305868  0.391046  ]\n",
      "ACTIONS: [0.01960097 0.23725119 0.5978034  0.17553386]\n",
      "Total score (averaged over agents) this episode: 0.026999999396502973\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "scores = np.zeros(env.agent_count)\n",
    "states = env.states\n",
    "for i in range(30):\n",
    "    actions = d4pg_agent.act(states)\n",
    "    print(\"ACTIONS:\", actions[1])\n",
    "    next_states, rewards, dones = env.step(actions)\n",
    "    scores += rewards\n",
    "    states = next_states\n",
    "    if np.any(dones):\n",
    "        break\n",
    "    i += 1\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out Critic scores without training\n",
    "<i> Test the <b>Critic</b> network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "scores = np.zeros(env.agent_count)\n",
    "states = env.states\n",
    "for i in range(10):\n",
    "    actions = d4pg_agent.act(states) \n",
    "    next_states, rewards, dones = env.step(actions)\n",
    "    scores += rewards\n",
    "    q, probs = d4pg_agent.critic(next_states, torch.from_numpy(actions))\n",
    "    print(probs[0])\n",
    "    print(q[0])\n",
    "    #print(values.sample())\n",
    "    states = next_states\n",
    "    if np.any(dones):\n",
    "        break\n",
    "    i += 1\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states.unsqueeze(0).shape, torch.from_numpy(actions).unsqueeze(0).shape, torch.tensor(rewards).unsqueeze(0).unsqueeze(-1).shape, next_states.unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 33]) torch.Size([20, 4]) torch.Size([20, 1]) torch.Size([20, 33])\n"
     ]
    }
   ],
   "source": [
    "print(states.shape, torch.from_numpy(actions).shape, torch.tensor(rewards).unsqueeze(-1).shape, next_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([660, 1])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = states.view(-1,1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.7552, -0.9905,  2.8673,  3.9994,  2.9695,  2.9995,  2.9835,  3.2856,\n",
       "         2.9925,  3.2750,  4.1036,  2.9579,  1.8526,  3.0248, -6.8912,  2.1844,\n",
       "         3.9922,  3.0747,  3.0126,  2.9010,  2.7187,  3.1661,  2.6261,  3.1690,\n",
       "         2.4122,  2.0907,  6.5273,  2.0000, -4.1804,  3.0000,  4.0000,  3.0000,\n",
       "         2.2210])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = list(map(list, zip(states, actions, rewards, next_states)))\n",
    "y = t[0][0] + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([ 0.7552, -2.9905,  0.8673,  1.9994,  0.9695,  0.9995,  0.9835,  1.2856,\n",
       "           0.9925,  1.2750,  2.1036,  0.9579, -0.1474,  1.0248, -8.8912,  0.1844,\n",
       "           1.9922,  1.0747,  1.0126,  0.9010,  0.7187,  1.1661,  0.6261,  1.1690,\n",
       "           0.4122,  0.0907,  4.5273,  0.0000, -6.1804,  1.0000,  2.0000,  1.0000,\n",
       "           0.2210]),\n",
       "  array([-0.1586271 ,  0.3516324 , -0.18842453, -0.3236364 ], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([ 0.7552, -2.9905,  0.8673,  1.9994,  0.9695,  0.9995,  0.9835,  1.2856,\n",
       "           0.9925,  1.2750,  2.1036,  0.9579, -0.1474,  1.0248, -8.8912,  0.1844,\n",
       "           1.9922,  1.0747,  1.0126,  0.9010,  0.7187,  1.1661,  0.6261,  1.1690,\n",
       "           0.4122,  0.0907,  4.5273,  0.0000, -6.1804,  1.0000,  2.0000,  1.0000,\n",
       "           0.2210])),\n",
       " (tensor([-1.0263e+00, -3.8364e+00,  4.8712e-01,  9.8973e-01, -1.2846e-01,\n",
       "           8.0743e-03,  6.2259e-02, -5.1829e-01, -1.5306e-02, -1.3203e-01,\n",
       "          -5.1700e-01,  3.6635e-01,  1.9870e+00, -6.2171e-01, -9.1210e+00,\n",
       "          -5.0804e-01,  9.3901e-01,  1.6867e-01,  1.3835e-01, -2.6582e-01,\n",
       "           1.5648e+00, -5.4986e-01, -7.8519e-02, -1.3028e-01,  3.5144e+00,\n",
       "          -1.2650e+00,  5.5918e+00, -1.0000e+00,  5.7212e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -7.4138e-01]),\n",
       "  array([ 0.13277127, -0.178421  ,  0.28213504,  0.1324235 ], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([-1.0263e+00, -3.8364e+00,  4.8712e-01,  9.8973e-01, -1.2846e-01,\n",
       "           8.0743e-03,  6.2259e-02, -5.1829e-01, -1.5306e-02, -1.3203e-01,\n",
       "          -5.1700e-01,  3.6635e-01,  1.9870e+00, -6.2171e-01, -9.1210e+00,\n",
       "          -5.0804e-01,  9.3901e-01,  1.6867e-01,  1.3835e-01, -2.6582e-01,\n",
       "           1.5648e+00, -5.4986e-01, -7.8519e-02, -1.3028e-01,  3.5144e+00,\n",
       "          -1.2650e+00,  5.5918e+00, -1.0000e+00,  5.7212e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -7.4138e-01])),\n",
       " (tensor([ 0.6646, -3.7988,  1.0657,  0.9873,  0.0822, -0.0113,  0.1352,  0.2116,\n",
       "           0.0361,  0.1274,  0.5252, -0.1457, -0.8311, -0.0148, -9.3283,  1.1971,\n",
       "           0.9703, -0.1925, -0.0709, -0.1281, -0.5102,  0.1331, -0.5183, -1.2864,\n",
       "           0.1013,  0.8090,  3.6385, -1.0000, -7.1247,  0.0000,  1.0000,  0.0000,\n",
       "          -0.0263]),\n",
       "  array([-0.01094247, -0.5078383 ,  0.22648595,  0.18347156], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([ 0.6646, -3.7988,  1.0657,  0.9873,  0.0822, -0.0113,  0.1352,  0.2116,\n",
       "           0.0361,  0.1274,  0.5252, -0.1457, -0.8311, -0.0148, -9.3283,  1.1971,\n",
       "           0.9703, -0.1925, -0.0709, -0.1281, -0.5102,  0.1331, -0.5183, -1.2864,\n",
       "           0.1013,  0.8090,  3.6385, -1.0000, -7.1247,  0.0000,  1.0000,  0.0000,\n",
       "          -0.0263])),\n",
       " (tensor([ 0.9525, -3.6088,  1.4446,  0.9751,  0.1172, -0.0225,  0.1870, -0.5461,\n",
       "          -0.0676, -0.1752, -0.7326,  0.5975,  2.0535, -0.0386, -8.1170,  0.8263,\n",
       "           0.8633, -0.2239, -0.2332, -0.3876,  1.9804, -0.1778,  0.1524, -0.4314,\n",
       "           5.4112, -2.3333,  7.8074, -1.0000, -1.7449,  0.0000,  1.0000,  0.0000,\n",
       "          -0.1850]),\n",
       "  array([ 0.11397772, -0.10847127,  0.34600392,  0.02532043], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([ 0.9525, -3.6088,  1.4446,  0.9751,  0.1172, -0.0225,  0.1870, -0.5461,\n",
       "          -0.0676, -0.1752, -0.7326,  0.5975,  2.0535, -0.0386, -8.1170,  0.8263,\n",
       "           0.8633, -0.2239, -0.2332, -0.3876,  1.9804, -0.1778,  0.1524, -0.4314,\n",
       "           5.4112, -2.3333,  7.8074, -1.0000, -1.7449,  0.0000,  1.0000,  0.0000,\n",
       "          -0.1850])),\n",
       " (tensor([ 2.6061e-01, -3.9903e+00,  1.1285e-01,  9.9938e-01,  3.2426e-02,\n",
       "          -4.7889e-04,  1.4060e-02,  4.5776e-01,  1.8480e-02,  4.9482e-01,\n",
       "           1.9877e+00,  4.0779e-02, -1.8403e+00,  2.9504e-01, -9.9770e+00,\n",
       "           5.5996e-02,  9.9936e-01, -2.6612e-02, -3.2352e-03, -2.3610e-02,\n",
       "          -8.7469e-01,  3.9442e-02, -9.4941e-01, -7.5947e-01, -3.4819e-02,\n",
       "           6.7935e-01,  5.8625e-03, -1.0000e+00, -8.0000e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  9.2395e-01]),\n",
       "  array([ 0.08797486,  0.2859372 , -0.16093422, -0.62292   ], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([ 2.6061e-01, -3.9903e+00,  1.1285e-01,  9.9938e-01,  3.2426e-02,\n",
       "          -4.7889e-04,  1.4060e-02,  4.5776e-01,  1.8480e-02,  4.9482e-01,\n",
       "           1.9877e+00,  4.0779e-02, -1.8403e+00,  2.9504e-01, -9.9770e+00,\n",
       "           5.5996e-02,  9.9936e-01, -2.6612e-02, -3.2352e-03, -2.3610e-02,\n",
       "          -8.7469e-01,  3.9442e-02, -9.4941e-01, -7.5947e-01, -3.4819e-02,\n",
       "           6.7935e-01,  5.8625e-03, -1.0000e+00, -8.0000e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  9.2395e-01])),\n",
       " (tensor([-9.1432e-01, -3.5675e+00, -1.5669e+00,  9.7244e-01, -1.1206e-01,\n",
       "          -2.3404e-02, -2.0310e-01,  2.8603e-01, -4.2155e-03,  9.8032e-03,\n",
       "           4.1772e-02,  4.3335e-01, -1.0324e+00,  2.0787e-01, -8.1391e+00,\n",
       "          -1.2675e+00,  8.7498e-01,  2.5542e-01, -2.2389e-01,  3.4503e-01,\n",
       "          -6.5736e-01,  4.2322e-01,  3.0342e-01,  1.8566e+00,  2.9827e+00,\n",
       "          -1.0434e+00,  6.0918e+00, -1.0000e+00,  5.1855e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  1.6487e-01]),\n",
       "  array([ 0.22669405,  0.43756223,  0.1028657 , -0.04236976], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([-9.1432e-01, -3.5675e+00, -1.5669e+00,  9.7244e-01, -1.1206e-01,\n",
       "          -2.3404e-02, -2.0310e-01,  2.8603e-01, -4.2155e-03,  9.8032e-03,\n",
       "           4.1772e-02,  4.3335e-01, -1.0324e+00,  2.0787e-01, -8.1391e+00,\n",
       "          -1.2675e+00,  8.7498e-01,  2.5542e-01, -2.2389e-01,  3.4503e-01,\n",
       "          -6.5736e-01,  4.2322e-01,  3.0342e-01,  1.8566e+00,  2.9827e+00,\n",
       "          -1.0434e+00,  6.0918e+00, -1.0000e+00,  5.1855e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  1.6487e-01])),\n",
       " (tensor([ 0.5218, -3.7226, -1.3720,  0.9825,  0.0640,  0.0114, -0.1744,  0.4327,\n",
       "           0.0552, -0.1547, -0.6545,  0.4966, -1.6531, -0.2753, -8.8982, -1.0104,\n",
       "           0.9411, -0.1802,  0.1061,  0.2656, -0.8592,  0.1766,  0.2372,  0.0537,\n",
       "           2.1534,  0.4906,  7.6931, -1.0000,  2.1947,  0.0000,  1.0000,  0.0000,\n",
       "           0.9769]),\n",
       "  array([-0.21535067,  0.2018065 , -0.51266366,  0.30229083], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([ 0.5218, -3.7226, -1.3720,  0.9825,  0.0640,  0.0114, -0.1744,  0.4327,\n",
       "           0.0552, -0.1547, -0.6545,  0.4966, -1.6531, -0.2753, -8.8982, -1.0104,\n",
       "           0.9411, -0.1802,  0.1061,  0.2656, -0.8592,  0.1766,  0.2372,  0.0537,\n",
       "           2.1534,  0.4906,  7.6931, -1.0000,  2.1947,  0.0000,  1.0000,  0.0000,\n",
       "           0.9769])),\n",
       " (tensor([ 1.6144e-01, -3.8136e+00, -1.1993e+00,  9.8833e-01,  1.9853e-02,\n",
       "           3.0368e-03, -1.5099e-01, -1.7388e-01, -6.3844e-02,  2.0157e-01,\n",
       "           8.4945e-01, -1.8180e-01,  6.7517e-01, -3.2658e-01, -9.0656e+00,\n",
       "          -3.8707e-01,  9.4673e-01, -9.2066e-02,  4.6680e-02,  3.0505e-01,\n",
       "           4.4198e-02, -5.2097e-01, -4.3615e-01, -1.3946e+00, -6.1042e-02,\n",
       "           5.8109e-01, -1.1249e+00, -1.0000e+00, -7.9205e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -9.7291e-01]),\n",
       "  array([-0.06774393, -0.04633397,  0.25774515,  0.37463316], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([ 1.6144e-01, -3.8136e+00, -1.1993e+00,  9.8833e-01,  1.9853e-02,\n",
       "           3.0368e-03, -1.5099e-01, -1.7388e-01, -6.3844e-02,  2.0157e-01,\n",
       "           8.4945e-01, -1.8180e-01,  6.7517e-01, -3.2658e-01, -9.0656e+00,\n",
       "          -3.8707e-01,  9.4673e-01, -9.2066e-02,  4.6680e-02,  3.0505e-01,\n",
       "           4.4198e-02, -5.2097e-01, -4.3615e-01, -1.3946e+00, -6.1042e-02,\n",
       "           5.8109e-01, -1.1249e+00, -1.0000e+00, -7.9205e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -9.7291e-01])),\n",
       " (tensor([-9.7616e-02, -3.9797e+00,  3.9288e-01,  9.9873e-01, -1.2127e-02,\n",
       "           5.9352e-04,  4.8934e-02, -2.0775e-02, -4.0461e-02, -4.1329e-01,\n",
       "          -1.6692e+00,  3.4703e-02,  8.0511e-02,  8.9073e-02, -9.7247e+00,\n",
       "          -4.6203e-01,  9.7966e-01,  4.1353e-02,  1.4024e-02, -1.9584e-01,\n",
       "           4.3281e-01, -4.7720e-01,  6.4275e-01,  5.2983e-01,  9.8808e-01,\n",
       "          -1.4903e+00,  5.2815e-01, -1.0000e+00,  7.9825e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -3.8037e-01]),\n",
       "  array([ 0.2754066 , -0.00879051, -0.43468553,  0.15757714], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([-9.7616e-02, -3.9797e+00,  3.9288e-01,  9.9873e-01, -1.2127e-02,\n",
       "           5.9352e-04,  4.8934e-02, -2.0775e-02, -4.0461e-02, -4.1329e-01,\n",
       "          -1.6692e+00,  3.4703e-02,  8.0511e-02,  8.9073e-02, -9.7247e+00,\n",
       "          -4.6203e-01,  9.7966e-01,  4.1353e-02,  1.4024e-02, -1.9584e-01,\n",
       "           4.3281e-01, -4.7720e-01,  6.4275e-01,  5.2983e-01,  9.8808e-01,\n",
       "          -1.4903e+00,  5.2815e-01, -1.0000e+00,  7.9825e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -3.8037e-01])),\n",
       " (tensor([ 4.7592e-01, -3.8940e+00,  7.8618e-01,  9.9334e-01,  5.9008e-02,\n",
       "          -5.8374e-03,  9.8770e-02, -6.3347e-01,  8.7547e-02,  4.6613e-01,\n",
       "           1.8955e+00,  6.7161e-01,  2.4498e+00,  7.7523e-01, -9.7718e+00,\n",
       "           8.6388e-01,  9.9608e-01, -7.4832e-03, -2.2128e-02, -8.5276e-02,\n",
       "           7.2382e-01,  4.0178e-01, -6.0037e-01,  3.8887e-01,  1.6894e+00,\n",
       "           1.1019e+00, -2.5802e+00, -1.0000e+00,  7.5725e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  2.5462e-01]),\n",
       "  array([-0.5195607 , -0.00299228,  0.02110956,  0.23100446], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([ 4.7592e-01, -3.8940e+00,  7.8618e-01,  9.9334e-01,  5.9008e-02,\n",
       "          -5.8374e-03,  9.8770e-02, -6.3347e-01,  8.7547e-02,  4.6613e-01,\n",
       "           1.8955e+00,  6.7161e-01,  2.4498e+00,  7.7523e-01, -9.7718e+00,\n",
       "           8.6388e-01,  9.9608e-01, -7.4832e-03, -2.2128e-02, -8.5276e-02,\n",
       "           7.2382e-01,  4.0178e-01, -6.0037e-01,  3.8887e-01,  1.6894e+00,\n",
       "           1.1019e+00, -2.5802e+00, -1.0000e+00,  7.5725e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  2.5462e-01])),\n",
       " (tensor([-3.5446e-02, -3.9995e+00, -7.8308e-02,  9.9994e-01, -4.4077e-03,\n",
       "          -6.4039e-05, -9.7399e-03, -3.3794e-01,  1.6547e-02, -6.3246e-01,\n",
       "          -2.5436e+00, -4.5268e-02,  1.3579e+00,  8.2506e-02, -9.9296e+00,\n",
       "          -7.6974e-01,  9.9406e-01,  2.3876e-02,  3.1508e-03, -1.0613e-01,\n",
       "           7.9819e-01, -3.0604e-01,  1.0058e+00,  2.1896e-01,  7.3860e-01,\n",
       "          -1.0785e+00,  7.7472e+00, -1.0000e+00, -1.9953e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  6.3608e-01]),\n",
       "  array([-0.57649106, -0.19827737,  0.02246212,  0.12793845], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([-3.5446e-02, -3.9995e+00, -7.8308e-02,  9.9994e-01, -4.4077e-03,\n",
       "          -6.4039e-05, -9.7399e-03, -3.3794e-01,  1.6547e-02, -6.3246e-01,\n",
       "          -2.5436e+00, -4.5268e-02,  1.3579e+00,  8.2506e-02, -9.9296e+00,\n",
       "          -7.6974e-01,  9.9406e-01,  2.3876e-02,  3.1508e-03, -1.0613e-01,\n",
       "           7.9819e-01, -3.0604e-01,  1.0058e+00,  2.1896e-01,  7.3860e-01,\n",
       "          -1.0785e+00,  7.7472e+00, -1.0000e+00, -1.9953e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  6.3608e-01])),\n",
       " (tensor([ 3.3766e-01, -3.9839e+00,  1.4257e-01,  9.9896e-01,  4.2026e-02,\n",
       "          -7.0931e-04,  1.7774e-02, -7.1252e-01,  1.1900e-02,  5.5458e-01,\n",
       "           2.2244e+00,  2.2442e-01,  2.8530e+00, -3.3348e-02, -9.8846e+00,\n",
       "          -1.3063e-01,  9.9239e-01, -1.0373e-01, -1.3457e-02, -6.4999e-02,\n",
       "           1.2232e+00,  3.5333e-01, -1.2836e+00, -1.8749e+00,  2.0008e+00,\n",
       "          -6.3290e-02,  6.0437e+00, -1.0000e+00,  5.2416e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  3.5163e-01]),\n",
       "  array([ 0.27713498, -0.17318732,  0.03113382, -0.2160224 ], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([ 3.3766e-01, -3.9839e+00,  1.4257e-01,  9.9896e-01,  4.2026e-02,\n",
       "          -7.0931e-04,  1.7774e-02, -7.1252e-01,  1.1900e-02,  5.5458e-01,\n",
       "           2.2244e+00,  2.2442e-01,  2.8530e+00, -3.3348e-02, -9.8846e+00,\n",
       "          -1.3063e-01,  9.9239e-01, -1.0373e-01, -1.3457e-02, -6.4999e-02,\n",
       "           1.2232e+00,  3.5333e-01, -1.2836e+00, -1.8749e+00,  2.0008e+00,\n",
       "          -6.3290e-02,  6.0437e+00, -1.0000e+00,  5.2416e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  3.5163e-01])),\n",
       " (tensor([ 2.7899e-01, -3.7831e+00, -1.2728e+00,  9.8640e-01,  3.4270e-02,\n",
       "           5.5734e-03, -1.6068e-01,  4.3353e-01, -6.5717e-02,  2.0213e-01,\n",
       "           8.5265e-01,  5.9072e-01, -1.6367e+00, -2.0547e-01, -9.3893e+00,\n",
       "          -1.2952e+00,  9.7963e-01, -1.1122e-01,  4.0043e-02,  1.6231e-01,\n",
       "          -5.7651e-01, -2.7024e-01, -2.4085e-01,  1.3318e-01,  2.0427e+00,\n",
       "          -7.4752e-01, -1.2780e+00, -1.0000e+00,  7.8973e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  6.9518e-01]),\n",
       "  array([ 0.22202246,  0.190476  , -0.01045028,  0.40530643], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([ 2.7899e-01, -3.7831e+00, -1.2728e+00,  9.8640e-01,  3.4270e-02,\n",
       "           5.5734e-03, -1.6068e-01,  4.3353e-01, -6.5717e-02,  2.0213e-01,\n",
       "           8.5265e-01,  5.9072e-01, -1.6367e+00, -2.0547e-01, -9.3893e+00,\n",
       "          -1.2952e+00,  9.7963e-01, -1.1122e-01,  4.0043e-02,  1.6231e-01,\n",
       "          -5.7651e-01, -2.7024e-01, -2.4085e-01,  1.3318e-01,  2.0427e+00,\n",
       "          -7.4752e-01, -1.2780e+00, -1.0000e+00,  7.8973e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  6.9518e-01])),\n",
       " (tensor([ 1.0304e+00, -3.8615e+00, -1.8755e-01,  9.9132e-01,  1.2921e-01,\n",
       "           3.1348e-03, -2.3942e-02, -5.6813e-01, -1.5201e-02,  2.5430e-01,\n",
       "           9.9123e-01,  1.2526e-01,  2.2220e+00,  1.5026e-01, -9.1581e+00,\n",
       "           4.0101e-01,  9.4310e-01, -2.7443e-01,  1.0114e-01,  1.5822e-01,\n",
       "           1.3597e+00, -6.2756e-02, -9.6199e-01, -1.7845e+00,  9.0013e-01,\n",
       "          -1.1328e+00,  6.5101e+00, -1.0000e+00, -4.6496e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -9.1163e-01]),\n",
       "  array([-0.03466215, -0.00350839,  0.47867078, -0.19798657], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([ 1.0304e+00, -3.8615e+00, -1.8755e-01,  9.9132e-01,  1.2921e-01,\n",
       "           3.1348e-03, -2.3942e-02, -5.6813e-01, -1.5201e-02,  2.5430e-01,\n",
       "           9.9123e-01,  1.2526e-01,  2.2220e+00,  1.5026e-01, -9.1581e+00,\n",
       "           4.0101e-01,  9.4310e-01, -2.7443e-01,  1.0114e-01,  1.5822e-01,\n",
       "           1.3597e+00, -6.2756e-02, -9.6199e-01, -1.7845e+00,  9.0013e-01,\n",
       "          -1.1328e+00,  6.5101e+00, -1.0000e+00, -4.6496e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -9.1163e-01])),\n",
       " (tensor([ 2.5239e-01, -3.9897e+00, -1.4987e-01,  9.9933e-01,  3.1399e-02,\n",
       "           6.1158e-04, -1.8673e-02, -4.8764e-01, -2.3890e-02,  5.0520e-01,\n",
       "           2.0305e+00,  1.4628e-02,  1.9606e+00, -7.0533e-03, -9.6668e+00,\n",
       "           1.0020e+00,  9.7283e-01, -6.9768e-02,  3.0761e-02,  2.1862e-01,\n",
       "           3.4892e-01, -6.0258e-01, -7.7508e-01, -6.9331e-01, -1.9174e-01,\n",
       "           1.6843e+00,  1.5840e+00, -1.0000e+00,  7.8416e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -4.1450e-01]),\n",
       "  array([-0.37863007, -0.00953302, -0.16687672,  0.00342777], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([ 2.5239e-01, -3.9897e+00, -1.4987e-01,  9.9933e-01,  3.1399e-02,\n",
       "           6.1158e-04, -1.8673e-02, -4.8764e-01, -2.3890e-02,  5.0520e-01,\n",
       "           2.0305e+00,  1.4628e-02,  1.9606e+00, -7.0533e-03, -9.6668e+00,\n",
       "           1.0020e+00,  9.7283e-01, -6.9768e-02,  3.0761e-02,  2.1862e-01,\n",
       "           3.4892e-01, -6.0258e-01, -7.7508e-01, -6.9331e-01, -1.9174e-01,\n",
       "           1.6843e+00,  1.5840e+00, -1.0000e+00,  7.8416e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -4.1450e-01])),\n",
       " (tensor([-4.9412e-01, -3.9594e+00,  2.9496e-01,  9.9742e-01, -6.1521e-02,\n",
       "           2.3160e-03,  3.6922e-02,  4.6031e-01, -7.4144e-02, -8.9335e-01,\n",
       "          -3.5842e+00,  2.2672e-01, -1.8656e+00, -1.4569e-01, -9.6598e+00,\n",
       "           1.5469e+00,  9.7610e-01,  1.1528e-01, -3.8759e-02,  1.8013e-01,\n",
       "          -1.9192e+00,  1.0714e+00,  1.6753e+00,  2.1732e+00,  4.5806e+00,\n",
       "           3.7252e+00,  7.5810e+00, -1.0000e+00,  2.5551e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  9.8436e-01]),\n",
       "  array([-0.24355145,  0.01954244, -0.3413981 ,  0.46485853], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([-4.9412e-01, -3.9594e+00,  2.9496e-01,  9.9742e-01, -6.1521e-02,\n",
       "           2.3160e-03,  3.6922e-02,  4.6031e-01, -7.4144e-02, -8.9335e-01,\n",
       "          -3.5842e+00,  2.2672e-01, -1.8656e+00, -1.4569e-01, -9.6598e+00,\n",
       "           1.5469e+00,  9.7610e-01,  1.1528e-01, -3.8759e-02,  1.8013e-01,\n",
       "          -1.9192e+00,  1.0714e+00,  1.6753e+00,  2.1732e+00,  4.5806e+00,\n",
       "           3.7252e+00,  7.5810e+00, -1.0000e+00,  2.5551e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  9.8436e-01])),\n",
       " (tensor([-1.5450e-04, -3.8150e+00,  1.2068e+00,  9.8840e-01, -2.1922e-05,\n",
       "          -1.7577e-05,  1.5184e-01, -3.1997e-01, -1.9673e-01, -6.3897e-01,\n",
       "          -2.6877e+00,  3.4419e-01,  1.2399e+00, -8.6956e-02, -9.2822e+00,\n",
       "           6.1863e-01,  9.6642e-01, -1.3883e-02, -3.8372e-03, -2.5657e-01,\n",
       "           5.9545e-01, -1.0328e+00,  8.8167e-01,  9.6779e-01,  1.6741e+00,\n",
       "          -4.0124e-01,  7.6232e+00, -1.0000e+00, -2.4263e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  1.6370e-02]),\n",
       "  array([-0.39288974, -0.07894687,  0.43174323,  0.1877066 ], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([-1.5450e-04, -3.8150e+00,  1.2068e+00,  9.8840e-01, -2.1922e-05,\n",
       "          -1.7577e-05,  1.5184e-01, -3.1997e-01, -1.9673e-01, -6.3897e-01,\n",
       "          -2.6877e+00,  3.4419e-01,  1.2399e+00, -8.6956e-02, -9.2822e+00,\n",
       "           6.1863e-01,  9.6642e-01, -1.3883e-02, -3.8372e-03, -2.5657e-01,\n",
       "           5.9545e-01, -1.0328e+00,  8.8167e-01,  9.6779e-01,  1.6741e+00,\n",
       "          -4.0124e-01,  7.6232e+00, -1.0000e+00, -2.4263e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  1.6370e-02])),\n",
       " (tensor([-3.4402e-01, -3.9722e+00, -3.2533e-01,  9.9826e-01, -4.2791e-02,\n",
       "          -1.7500e-03, -4.0608e-02, -2.0659e-01,  3.7777e-02, -4.4065e-01,\n",
       "          -1.7727e+00,  6.5280e-02,  8.3673e-01, -3.9551e-01, -9.7823e+00,\n",
       "           4.0542e-01,  9.8550e-01,  3.0885e-02, -2.2761e-02,  1.6531e-01,\n",
       "           1.8168e-02,  4.1339e-01,  6.8382e-01,  3.7998e-01,  2.4863e-01,\n",
       "           1.2874e+00,  6.1322e+00, -1.0000e+00,  5.1377e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -3.2394e-01]),\n",
       "  array([-0.35789135, -0.15278007, -0.2198256 , -0.14238979], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([-3.4402e-01, -3.9722e+00, -3.2533e-01,  9.9826e-01, -4.2791e-02,\n",
       "          -1.7500e-03, -4.0608e-02, -2.0659e-01,  3.7777e-02, -4.4065e-01,\n",
       "          -1.7727e+00,  6.5280e-02,  8.3673e-01, -3.9551e-01, -9.7823e+00,\n",
       "           4.0542e-01,  9.8550e-01,  3.0885e-02, -2.2761e-02,  1.6531e-01,\n",
       "           1.8168e-02,  4.1339e-01,  6.8382e-01,  3.7998e-01,  2.4863e-01,\n",
       "           1.2874e+00,  6.1322e+00, -1.0000e+00,  5.1377e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -3.2394e-01])),\n",
       " (tensor([ 3.6776e-01, -3.9039e+00,  7.9403e-01,  9.9398e-01,  4.5562e-02,\n",
       "          -4.5551e-03,  9.9559e-02, -5.8414e-01,  2.8850e-02,  1.5147e-01,\n",
       "           6.1746e-01,  4.9161e-01,  2.2876e+00, -5.7072e-01, -9.3486e+00,\n",
       "           2.8701e-01,  9.5611e-01, -1.9622e-01, -7.0525e-02, -2.0588e-01,\n",
       "           1.3788e+00,  6.1676e-01, -8.3733e-01, -3.0670e+00,  4.4356e+00,\n",
       "          -1.9619e-01,  5.2022e+00, -1.0000e+00, -6.0776e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  6.6093e-01]),\n",
       "  array([-0.40165552, -0.21939856, -0.20279048, -0.07236854], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([ 3.6776e-01, -3.9039e+00,  7.9403e-01,  9.9398e-01,  4.5562e-02,\n",
       "          -4.5551e-03,  9.9559e-02, -5.8414e-01,  2.8850e-02,  1.5147e-01,\n",
       "           6.1746e-01,  4.9161e-01,  2.2876e+00, -5.7072e-01, -9.3486e+00,\n",
       "           2.8701e-01,  9.5611e-01, -1.9622e-01, -7.0525e-02, -2.0588e-01,\n",
       "           1.3788e+00,  6.1676e-01, -8.3733e-01, -3.0670e+00,  4.4356e+00,\n",
       "          -1.9619e-01,  5.2022e+00, -1.0000e+00, -6.0776e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  6.6093e-01])),\n",
       " (tensor([-4.3461e-01, -3.8685e+00,  9.2382e-01,  9.9175e-01, -5.3767e-02,\n",
       "           6.2801e-03,  1.1619e-01, -4.1298e-01, -1.0610e-01, -4.6304e-01,\n",
       "          -1.9005e+00,  5.5281e-01,  1.5683e+00, -1.0705e-01, -9.2821e+00,\n",
       "           1.0302e-01,  9.5596e-01,  9.4852e-02,  6.6807e-02, -2.6959e-01,\n",
       "           1.3170e+00, -9.6411e-01,  7.4006e-01,  1.5764e+00,  4.4551e+00,\n",
       "          -1.4260e+00,  7.0034e+00, -1.0000e+00, -3.8668e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  9.7261e-01]),\n",
       "  array([-0.5206326 , -0.37337172,  0.19418246,  0.27217937], dtype=float32),\n",
       "  0.0,\n",
       "  tensor([-4.3461e-01, -3.8685e+00,  9.2382e-01,  9.9175e-01, -5.3767e-02,\n",
       "           6.2801e-03,  1.1619e-01, -4.1298e-01, -1.0610e-01, -4.6304e-01,\n",
       "          -1.9005e+00,  5.5281e-01,  1.5683e+00, -1.0705e-01, -9.2821e+00,\n",
       "           1.0302e-01,  9.5596e-01,  9.4852e-02,  6.6807e-02, -2.6959e-01,\n",
       "           1.3170e+00, -9.6411e-01,  7.4006e-01,  1.5764e+00,  4.4551e+00,\n",
       "          -1.4260e+00,  7.0034e+00, -1.0000e+00, -3.8668e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  9.7261e-01]))]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = deque(maxlen=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(n) < n.maxlen:\n",
    "    n.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "for actor in zip(*n): #zip(*n) is stacked_actors\n",
    "    states, actions, rewards, next_states = zip(*actor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = (1, 1, 1, 1, 1)\n",
    "# rewards = np.array(rewards)\n",
    "\n",
    "# rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = gamma**args.rollout * rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.      , 0.99    , 0.9801  , 0.970299])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.array([rewards[i] * gamma**i for i in range(args.rollout-1)])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.      , 0.99    , 0.9801  , 0.970299])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcount = args.rollout - 1\n",
    "r2 = np.fromiter((rewards[i] * gamma**i for i in range(rcount)), float, count=rcount)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [(states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn about how the Categorical Bellman step works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.random.randn(env.agent_count, env.action_size)\n",
    "actions = np.clip(actions, -1, 1).astype(np.float32)\n",
    "states = torch.from_numpy(env.states).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, probs, log_probs = critic(states, torch.from_numpy(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs.shape)\n",
    "print(log_probs.shape)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Container():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "c = Container()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.vmin = -10\n",
    "c.vmax = 10\n",
    "c.natoms = 51\n",
    "c.gamma = .99\n",
    "c.atoms = torch.linspace(vmin, vmax, natoms)\n",
    "c.delta_z = (vmax - vmin) / (natoms -1)\n",
    "c.r = torch.tensor(rewards).unsqueeze(-1)\n",
    "\n",
    "c.probs = probs.detach()\n",
    "c.q_next = (probs * atoms).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vars(x):\n",
    "    for arg in vars(x):\n",
    "        print(\"{}: {}\".format(arg.upper(), getattr(x, arg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.0000,  -9.6000,  -9.2000,  -8.8000,  -8.4000,  -8.0000,  -7.6000,\n",
       "         -7.2000,  -6.8000,  -6.4000,  -6.0000,  -5.6000,  -5.2000,  -4.8000,\n",
       "         -4.4000,  -4.0000,  -3.6000,  -3.2000,  -2.8000,  -2.4000,  -2.0000,\n",
       "         -1.6000,  -1.2000,  -0.8000,  -0.4000,   0.0000,   0.4000,   0.8000,\n",
       "          1.2000,   1.6000,   2.0000,   2.4000,   2.8000,   3.2000,   3.6000,\n",
       "          4.0000,   4.4000,   4.8000,   5.2000,   5.6000,   6.0000,   6.4000,\n",
       "          6.8000,   7.2000,   7.6000,   8.0000,   8.4000,   8.8000,   9.2000,\n",
       "          9.6000,  10.0000])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### projected atoms\n",
    "<html><i>\n",
    "<b>atoms.view(1,-1)</b> becomes shape [1, num_atoms]\n",
    "<br>\n",
    "<b>r</b> is unsqueezed in the last (-1) dimension, so it's shape [20,1]\n",
    "<br>\n",
    "the result is a tensor that holds an offset (projected) version of the atoms for each reward instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tz = projected atoms, atoms (values) projected by scaling and offsetting via the bellman equation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.9000, -9.5040, -9.1080,  ...,  9.1080,  9.5040,  9.9000],\n",
       "        [-9.9000, -9.5040, -9.1080,  ...,  9.1080,  9.5040,  9.9000],\n",
       "        [-9.9000, -9.5040, -9.1080,  ...,  9.1080,  9.5040,  9.9000],\n",
       "        ...,\n",
       "        [-9.9000, -9.5040, -9.1080,  ...,  9.1080,  9.5040,  9.9000],\n",
       "        [-9.9000, -9.5040, -9.1080,  ...,  9.1080,  9.5040,  9.9000],\n",
       "        [-9.9000, -9.5040, -9.1080,  ...,  9.1080,  9.5040,  9.9000]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz = c.r + c.gamma * c.atoms.view(1,-1)\n",
    "tz.clamp_(vmin, vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### computes \"bj\" from the pseudo-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25000095,  1.2399983 ,  2.2300005 ,  3.2200003 ,  4.21      ,\n",
       "        5.2       ,  6.1899996 ,  7.1800003 ,  8.169999  ,  9.160001  ,\n",
       "       10.15      , 11.139999  , 12.13      , 13.12      , 14.11      ,\n",
       "       15.099999  , 16.09      , 17.08      , 18.07      , 19.06      ,\n",
       "       20.050001  , 21.04      , 22.03      , 23.02      , 24.01      ,\n",
       "       25.        , 25.990002  , 26.98      , 27.97      , 28.960001  ,\n",
       "       29.949999  , 30.94      , 31.93      , 32.92      , 33.91      ,\n",
       "       34.899998  , 35.890003  , 36.88      , 37.87      , 38.86      ,\n",
       "       39.850002  , 40.839996  , 41.830006  , 42.82      , 43.81      ,\n",
       "       44.8       , 45.79      , 46.780003  , 47.770004  , 48.760002  ,\n",
       "       49.75      ], dtype=float32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = (tz - c.vmin) / c.delta_z\n",
    "b[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### l/u in the psuedocode are LOWER and UPPER bounds on the supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
      "        35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])\n"
     ]
    }
   ],
   "source": [
    "l = b.floor().long()\n",
    "u = b.ceil().long()\n",
    "print(l[0])\n",
    "print(u[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### m_l/m_u are computed in the pseudocode under \"distribute the probability of tz\", but still a bit opaque to me on how it should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01467833, 0.01493664, 0.01510203, 0.0153105 , 0.01546834,\n",
       "       0.01571159, 0.01590588, 0.0160307 , 0.01628518, 0.01649079,\n",
       "       0.01670613, 0.01687601, 0.01705097, 0.01730292, 0.01742529,\n",
       "       0.01766971, 0.01783578, 0.0180223 , 0.01823092, 0.01840046,\n",
       "       0.0186618 , 0.01879957, 0.01903829, 0.01920612, 0.0193745 ,\n",
       "       0.01964528, 0.00019637, 0.00039313, 0.00058676, 0.00078374,\n",
       "       0.00098073, 0.00117412, 0.00136963, 0.00156546, 0.00176948,\n",
       "       0.00196226, 0.00215623, 0.00235884, 0.00255588, 0.0027378 ,\n",
       "       0.00293237, 0.00312979, 0.00333509, 0.00352029, 0.00372426,\n",
       "       0.00392292, 0.00411897, 0.00432351, 0.00451106, 0.00469343,\n",
       "       0.0049065 ], dtype=float32)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version from GITHUB implementations\n",
    "\n",
    "gdml = (u.float() + (l == u).float() - b) * c.probs\n",
    "gdml[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0048928 , 0.00471679, 0.00451101, 0.00431835, 0.00411184,\n",
       "       0.00392789, 0.003731  , 0.00351894, 0.0033355 , 0.00314112,\n",
       "       0.00294813, 0.00274724, 0.00254785, 0.00235949, 0.00215368,\n",
       "       0.00196329, 0.00176398, 0.00156716, 0.00137221, 0.00117449,\n",
       "       0.00098222, 0.00078333, 0.00058883, 0.00039197, 0.00019571,\n",
       "       0.        , 0.01944361, 0.01926299, 0.01897159, 0.01881013,\n",
       "       0.01863343, 0.01839465, 0.01819655, 0.01800233, 0.01789142,\n",
       "       0.01765985, 0.01744645, 0.01729832, 0.0171046 , 0.01681799,\n",
       "       0.01661707, 0.01643098, 0.01628374, 0.01603686, 0.01587726,\n",
       "       0.01569162, 0.01549527, 0.01532905, 0.01510262, 0.01486269,\n",
       "       0.01471951], dtype=float32)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version from GITHUB implementations\n",
    "\n",
    "gdmu = (b - l.float()) * c.probs\n",
    "gdmu[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01467833,  1.0149367 ,  2.0151021 ,  3.0153105 ,  4.015468  ,\n",
       "        5.015712  ,  6.015906  ,  7.016031  ,  8.016285  ,  9.016491  ,\n",
       "       10.016706  , 11.016876  , 12.017051  , 13.0173025 , 14.017426  ,\n",
       "       15.01767   , 16.017836  , 17.018023  , 18.01823   , 19.0184    ,\n",
       "       20.018661  , 21.018799  , 22.01904   , 23.019207  , 24.019375  ,\n",
       "       25.        , 25.000196  , 26.000393  , 27.000587  , 28.000784  ,\n",
       "       29.00098   , 30.001175  , 31.00137   , 32.001564  , 33.00177   ,\n",
       "       34.00196   , 35.002155  , 36.002357  , 37.002556  , 38.00274   ,\n",
       "       39.002934  , 40.003128  , 41.003334  , 42.00352   , 43.003723  ,\n",
       "       44.00392   , 45.00412   , 46.004322  , 47.004513  , 48.004692  ,\n",
       "       49.004906  ], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version from the PAPER\n",
    "\n",
    "pdml = l.float() + (c.probs * (u.float()-b))\n",
    "pdml[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0048928,  2.0047169,  3.004511 ,  4.004318 ,  5.004112 ,\n",
       "        6.0039277,  7.003731 ,  8.003519 ,  9.003336 , 10.003141 ,\n",
       "       11.002948 , 12.002748 , 13.002548 , 14.002359 , 15.002153 ,\n",
       "       16.001963 , 17.001764 , 18.001568 , 19.001371 , 20.001175 ,\n",
       "       21.000982 , 22.000784 , 23.00059  , 24.000393 , 25.000196 ,\n",
       "       25.       , 26.019444 , 27.019262 , 28.018972 , 29.01881  ,\n",
       "       30.018633 , 31.018394 , 32.018196 , 33.018    , 34.01789  ,\n",
       "       35.01766  , 36.017445 , 37.0173   , 38.017105 , 39.01682  ,\n",
       "       40.016617 , 41.01643  , 42.016285 , 43.016037 , 44.015877 ,\n",
       "       45.01569  , 46.015495 , 47.015327 , 48.015102 , 49.014862 ,\n",
       "       50.01472  ], dtype=float32)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version from the PAPER\n",
    "\n",
    "pdmu = u.float() + (c.probs * (b - l.float()))\n",
    "pdmu[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_prob.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01957113, 0.01965343, 0.01961304, 0.01962886, 0.01958018,\n",
       "       0.01963948, 0.01963687, 0.01954965, 0.01962068, 0.01963191,\n",
       "       0.01965426, 0.01962326, 0.01959882, 0.0196624 , 0.01957897,\n",
       "       0.019633  , 0.01959976, 0.01958946, 0.01960313, 0.01957494,\n",
       "       0.01964402, 0.01958291, 0.01962711, 0.01959809, 0.01957021,\n",
       "       0.01964528, 0.01963998, 0.01965612, 0.01955835, 0.01959387,\n",
       "       0.01961417, 0.01956877, 0.01956618, 0.01956779, 0.0196609 ,\n",
       "       0.0196221 , 0.01960268, 0.01965716, 0.01966049, 0.01955579,\n",
       "       0.01954945, 0.01956077, 0.01961883, 0.01955715, 0.01960152,\n",
       "       0.01961454, 0.01961425, 0.01965257, 0.01961369, 0.01955612,\n",
       "       0.01962601], dtype=float32)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.probs[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01467833, 0.01982944, 0.01981882, 0.01982151, 0.01978669,\n",
       "       0.01982343, 0.01983377, 0.0197617 , 0.01980412, 0.01982629,\n",
       "       0.01984725, 0.01982415, 0.01979821, 0.01985077, 0.01978477,\n",
       "       0.01982339, 0.01979907, 0.01978629, 0.01979808, 0.01977267,\n",
       "       0.01983629, 0.0197818 , 0.01982162, 0.01979494, 0.01976647,\n",
       "       0.02003736, 0.01983674, 0.01984975, 0.01975532, 0.01979086,\n",
       "       0.01980755, 0.01976428, 0.01976201, 0.01977182, 0.01985367,\n",
       "       0.01981608, 0.01980529, 0.01985421, 0.0198424 , 0.01975036,\n",
       "       0.01974687, 0.01976607, 0.01980403, 0.01976112, 0.01980018,\n",
       "       0.01981059, 0.01981879, 0.01984012, 0.01979605, 0.0197692 ,\n",
       "       0.01471951])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_prob = torch.tensor(np.zeros(probs.size()))\n",
    "for i in range(target_prob.size(0)):\n",
    "    target_prob[i].index_add_(0, l[i].long(), gdml[i].double())\n",
    "    target_prob[i].index_add_(0, u[i].long(), gdmu[i].double())\n",
    "target_prob[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip dml and dmu together offset by 1 index and subtract 1, receive amount to add to probs!\n",
    "x = zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014678 0.019571 -0.00489\n",
      "0.019829 0.019653 0.000176\n",
      "0.019818 0.019613 0.000205\n",
      "0.019821 0.019628 0.000192\n",
      "0.019786 0.019580 0.000206\n",
      "0.019823 0.019639 0.000183\n",
      "0.019833 0.019636 0.000196\n",
      "0.019761 0.019549 0.000212\n",
      "0.019804 0.019620 0.000183\n",
      "0.019826 0.019631 0.000194\n",
      "0.019847 0.019654 0.000192\n",
      "0.019824 0.019623 0.000200\n",
      "0.019798 0.019598 0.000199\n",
      "0.019850 0.019662 0.000188\n",
      "0.019784 0.019578 0.000205\n",
      "0.019823 0.019633 0.000190\n",
      "0.019799 0.019599 0.000199\n",
      "0.019786 0.019589 0.000196\n",
      "0.019798 0.019603 0.000194\n",
      "0.019772 0.019574 0.000197\n",
      "0.019836 0.019644 0.000192\n",
      "0.019781 0.019582 0.000198\n",
      "0.019821 0.019627 0.000194\n",
      "0.019794 0.019598 0.000196\n",
      "0.019766 0.019570 0.000196\n",
      "0.020037 0.019645 0.000392\n",
      "0.019836 0.019639 0.000196\n",
      "0.019849 0.019656 0.000193\n",
      "0.019755 0.019558 0.000196\n",
      "0.019790 0.019593 0.000196\n",
      "0.019807 0.019614 0.000193\n",
      "0.019764 0.019568 0.000195\n",
      "0.019762 0.019566 0.000195\n",
      "0.019771 0.019567 0.000204\n",
      "0.019853 0.019660 0.000192\n",
      "0.019816 0.019622 0.000193\n",
      "0.019805 0.019602 0.000202\n",
      "0.019854 0.019657 0.000197\n",
      "0.019842 0.019660 0.000181\n",
      "0.019750 0.019555 0.000194\n",
      "0.019746 0.019549 0.000197\n",
      "0.019766 0.019560 0.000205\n",
      "0.019804 0.019618 0.000185\n",
      "0.019761 0.019557 0.000203\n",
      "0.019800 0.019601 0.000198\n",
      "0.019810 0.019614 0.000196\n",
      "0.019818 0.019614 0.000204\n",
      "0.019840 0.019652 0.000187\n",
      "0.019796 0.019613 0.000182\n",
      "0.019769 0.019556 0.000213\n",
      "0.014719 0.019626 -0.00490\n"
     ]
    }
   ],
   "source": [
    "for i in range(c.probs.size(1)):\n",
    "    t = target_prob[0].numpy()[i]\n",
    "    p = c.probs[0].numpy()[i]\n",
    "    pad = 8\n",
    "    print(str(t)[:pad], str(p)[:pad], str(t-p)[:pad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
