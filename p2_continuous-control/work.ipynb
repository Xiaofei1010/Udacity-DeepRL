{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><b><font size=10> CONTINUOUS CONTROL</font></b>\n",
    "#### <i>...implementation for Udacity Deep Reinforcement Learning \n",
    "<hr><hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Imports for the notebook\n",
    "This Notebook uses code from separate python files where most of the implementation is handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import environment as E\n",
    "from buffers import ReplayBuffer, nStepBuffer\n",
    "from agent import D4PG_Agent\n",
    "\n",
    "#from get_args import get_args\n",
    "\n",
    "import os.path\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "import importlib\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from unityagents import UnityEnvironment\n",
    "from collections import deque\n",
    "import torchvision.transforms as T\n",
    "import multiprocessing as multi\n",
    "multi.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually declare an ARGS class\n",
    "<i> For testing code in the notebook, to take the place of argparser in the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.train = True\n",
    "        self.nographics = False\n",
    "        self.num_eps = 10\n",
    "        self.rollout = 5\n",
    "        self.batchsize = 64\n",
    "        self.pretrain = 1000\n",
    "        \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Confirm that the args are all set the way we want them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: True\n",
      "NOGRAPHICS: False\n",
      "NUM_EPS: 10\n",
      "ROLLOUT: 5\n",
      "BATCHSIZE: 64\n",
      "PRETRAIN: 1000\n"
     ]
    }
   ],
   "source": [
    "for arg in vars(args):\n",
    "    if arg == \"sep\": continue\n",
    "    print(\"{}: {}\".format(arg.upper(), getattr(args, arg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the environment\n",
    "<i> & print a bit of information contained in the wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 33\n",
      "Action size: 4\n",
      "Num Agents: 20\n"
     ]
    }
   ],
   "source": [
    "env = E.Environment(args)\n",
    "print(\"State size:\", env.state_size)\n",
    "print(\"Action size:\", env.action_size)\n",
    "print(\"Num Agents:\", env.agent_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Test code as it's developed\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take random actions in the environment below \n",
    "<i>\n",
    "-to check that code is working<br>\n",
    "-to get familiar with the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.train = False\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.020499999541789292\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "scores = np.zeros(env.agent_count)\n",
    "states = env.states\n",
    "actions = np.zeros((20,4))\n",
    "for i in range(100):\n",
    "    #actions = np.random.randn(env.agent_count, env.action_size)\n",
    "    actions[:,3] += .01\n",
    "    actions = np.clip(actions, -1, 1)\n",
    "    next_states, rewards, dones = env.step(actions)\n",
    "    scores += rewards\n",
    "    states = next_states\n",
    "    if np.any(dones):\n",
    "        break\n",
    "    i += 1\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]]\n",
      "[[0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]]\n",
      "[[0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]\n",
      " [0.3 0.  0.  0. ]]\n",
      "[[0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0. ]]\n",
      "[[0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0. ]]\n",
      "[[0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]\n",
      " [0.6 0.  0.  0. ]]\n",
      "[[0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]]\n",
      "[[0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]]\n",
      "[[0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]\n",
      " [0.9 0.  0.  0. ]]\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "actions = np.zeros((20,4))\n",
    "for i in range(10):\n",
    "    actions[:,0] += .1\n",
    "    print(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force-reload modules as they're updated\n",
    "<i> This notebook was developed as the code is written in Atom, the below cell reloads the modules as they're needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent\n",
    "importlib.reload(agent)\n",
    "#importlib.reload(E)\n",
    "importlib.reload(models)\n",
    "from agent import D4PG_Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d4pg_agent = D4PG_Agent(env.state_size, env.action_size, env.agent_count)\n",
    "# print(d4pg_agent.__class__.__name__)\n",
    "# print(d4pg_agent.memory)\n",
    "# agent.initialize_memory(10, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "states = env.states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out Actor actions without training\n",
    "<i> Test the <b>Actor</b> network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIONS: [ 0.12072824 -0.08650129 -0.2426841   0.20263317]\n",
      "ACTIONS: [ 0.11929604  0.0774109   0.15026315 -0.14079183]\n",
      "ACTIONS: [-0.21552052  0.3036239  -0.05686849  0.16493551]\n",
      "ACTIONS: [-0.37239876  0.64675504 -0.02954452 -0.41759738]\n",
      "ACTIONS: [-0.40439492  0.49016446 -0.09638876  0.5759712 ]\n",
      "ACTIONS: [ 0.18600334 -0.13982823 -0.18315789 -0.1067877 ]\n",
      "ACTIONS: [ 0.10396563  0.20145947 -0.04876871  0.49385545]\n",
      "ACTIONS: [-0.18973796 -0.23842593 -0.01363463  0.26116577]\n",
      "ACTIONS: [ 0.12457623 -0.04857243  0.06835352 -0.2388278 ]\n",
      "ACTIONS: [-0.08805268 -0.5120842  -0.18368335 -0.21154818]\n",
      "ACTIONS: [ 0.22746587  0.29810438 -0.20771603 -0.5380932 ]\n",
      "ACTIONS: [ 0.32480836  0.5606363   0.04752121 -0.37489942]\n",
      "ACTIONS: [ 0.25482413 -0.12632596  0.11426903 -0.23253416]\n",
      "ACTIONS: [-0.04591284 -0.48473155 -0.12828822 -0.40005875]\n",
      "ACTIONS: [-0.12775998  0.27066866 -0.02793056  0.14100502]\n",
      "ACTIONS: [ 0.0389617  -0.6315945   0.14557207 -0.23061852]\n",
      "ACTIONS: [-0.28976026 -0.40605357  0.5128111   0.3156206 ]\n",
      "ACTIONS: [ 0.04737271 -0.36484262 -0.47021213 -0.02187341]\n",
      "ACTIONS: [-0.4216092   0.15118648  0.03128338  0.11589441]\n",
      "ACTIONS: [ 0.01606118  0.5234255   0.28901285 -0.21220809]\n",
      "ACTIONS: [ 0.5250722  -0.16561697 -0.14654218  0.08694129]\n",
      "ACTIONS: [ 0.36524877 -0.00681528  0.25105527  0.06142449]\n",
      "ACTIONS: [ 0.48513132  0.2382872  -0.17689939  0.31031933]\n",
      "ACTIONS: [ 0.30648738  0.02770824 -0.17873181  0.04762455]\n",
      "ACTIONS: [-0.32926205 -0.3709646   0.20545831  0.08505697]\n",
      "ACTIONS: [ 0.06693208 -0.36707902  0.07644779  0.1119006 ]\n",
      "ACTIONS: [-1.         -0.04741302 -0.38507655 -0.03725885]\n",
      "ACTIONS: [ 0.22106649 -0.14138192  0.23810844 -0.2906935 ]\n",
      "ACTIONS: [ 0.22334993  0.29404452 -0.04155547 -0.14612043]\n",
      "ACTIONS: [-0.31963554 -0.4461267  -0.30007142 -0.00615189]\n",
      "ACTIONS: [-0.13366449 -0.2226991   0.3303915  -0.27068284]\n",
      "ACTIONS: [-0.04415014 -0.14551754 -0.32131237  0.27187738]\n",
      "ACTIONS: [ 0.4342598  -0.38873953 -0.38753417 -0.27253994]\n",
      "ACTIONS: [ 0.18032834  0.07462768  0.12816897 -0.0629931 ]\n",
      "ACTIONS: [ 0.71270835  0.16240747 -0.01864175 -0.21183746]\n",
      "ACTIONS: [-0.27315181 -0.20842376  0.15113765  0.13595015]\n",
      "ACTIONS: [ 0.01791976  0.05756683  0.20016502 -0.11446424]\n",
      "ACTIONS: [-0.12851964  0.5347632  -0.23530322 -0.34535116]\n",
      "ACTIONS: [0.13821794 0.5174551  0.26053464 0.09365007]\n",
      "ACTIONS: [ 0.15876238  0.503019   -0.02432686  0.00557923]\n",
      "ACTIONS: [-0.01297571  0.5648322  -0.09095738  0.0629812 ]\n",
      "ACTIONS: [-0.06447558 -0.23799656 -0.2852183   0.07028619]\n",
      "ACTIONS: [-0.43395257  0.0452313   0.17833775  0.20840147]\n",
      "ACTIONS: [ 0.05967616  0.0849917   0.31457388 -0.09193315]\n",
      "ACTIONS: [ 0.13781719 -0.50812846 -0.40135875 -0.40875077]\n",
      "ACTIONS: [-0.22618903 -0.06824914 -0.16521227  0.4225027 ]\n",
      "ACTIONS: [ 0.21166241  0.70958567 -0.07557392 -0.5496078 ]\n",
      "ACTIONS: [ 0.3458147   0.31176662  0.34754732 -0.4983181 ]\n",
      "ACTIONS: [-0.769729    0.2888823   0.32268023  0.56703484]\n",
      "ACTIONS: [ 0.42391065 -0.08311993  0.39025408 -0.06502116]\n",
      "ACTIONS: [ 0.27962738  0.14263286 -0.06177215  0.08429126]\n",
      "ACTIONS: [ 0.29337782 -0.3576529   0.13087739  0.12513973]\n",
      "ACTIONS: [ 0.04873787 -0.26305985 -0.05451235 -0.5353533 ]\n",
      "ACTIONS: [-0.33282256  0.3198431  -0.17298396  0.45262343]\n",
      "ACTIONS: [ 0.5679735  -0.48414248 -0.57126415  0.3291875 ]\n",
      "ACTIONS: [-0.22942573 -0.15944242  0.12428928  0.2580234 ]\n",
      "ACTIONS: [ 0.10955698  0.03991408  0.1873713  -0.45172465]\n",
      "ACTIONS: [ 0.35275027  0.00641204 -0.19885124 -0.71200144]\n",
      "ACTIONS: [-0.07790359  0.42106625 -0.06504136 -0.59945023]\n",
      "ACTIONS: [-0.01903492  0.1502231   0.04516786  0.2645027 ]\n",
      "ACTIONS: [-0.04208948 -0.23583068 -0.3027693   0.02875751]\n",
      "ACTIONS: [ 0.11839127 -0.35526547 -0.08245274  0.24794929]\n",
      "ACTIONS: [-0.6800787  -0.48854655  0.4927831   0.32590875]\n",
      "ACTIONS: [-0.25366595  0.06205123 -0.3411436   0.19157307]\n",
      "ACTIONS: [ 0.09181947 -0.04342423  0.20018746 -0.09486665]\n",
      "ACTIONS: [-0.2673768  -0.22917771  0.01782488 -0.22003579]\n",
      "ACTIONS: [-0.00962315 -0.54040384 -0.0297155   0.6061525 ]\n",
      "ACTIONS: [ 0.40903232 -0.06678997  0.17330432  0.30477387]\n",
      "ACTIONS: [ 0.319052    0.20521122 -0.14733939 -0.5790094 ]\n",
      "ACTIONS: [ 0.04184839 -0.3890094   0.315954   -0.05233695]\n",
      "ACTIONS: [-0.20236386 -0.03345454  0.12621924 -0.41441184]\n",
      "ACTIONS: [ 0.09802423  0.08833572 -0.15400536  0.13180089]\n",
      "ACTIONS: [ 0.38873604 -0.5156309  -0.1521238   0.3640067 ]\n",
      "ACTIONS: [ 0.36035475 -0.5414669  -0.4999062  -0.3080816 ]\n",
      "ACTIONS: [ 0.56373376 -0.19451483 -0.03451609  0.28301698]\n",
      "ACTIONS: [0.05561407 0.19755049 0.17129329 0.34235597]\n",
      "ACTIONS: [ 0.5278799   0.28653768  0.26260802 -0.05397813]\n",
      "ACTIONS: [0.48767284 0.10613584 0.17681554 0.05513634]\n",
      "ACTIONS: [0.60768133 0.24555601 0.09480144 0.22957668]\n",
      "ACTIONS: [ 0.21570075  0.19259754 -0.13349421  0.02378745]\n",
      "ACTIONS: [0.6193738  0.02655462 0.14264272 0.2613116 ]\n",
      "ACTIONS: [ 0.475745    0.29863054 -0.03646495  0.34418547]\n",
      "ACTIONS: [-0.29618782  0.32685718  0.02951539  0.06365198]\n",
      "ACTIONS: [-0.10052114  0.43530935  0.22925463  0.01088234]\n",
      "ACTIONS: [-0.05444481 -0.17154554  0.1167794   0.7679666 ]\n",
      "ACTIONS: [-0.20350663 -0.44245994 -0.0190886   0.15579931]\n",
      "ACTIONS: [0.29012436 0.16497733 0.3654102  0.39193213]\n",
      "ACTIONS: [ 0.11421129  0.2883962   0.10319533 -0.08114213]\n",
      "ACTIONS: [-0.03122737  0.11826081 -0.50668615  0.57303673]\n",
      "ACTIONS: [ 0.07085722 -0.47440276  0.0561147  -0.39485812]\n",
      "ACTIONS: [ 0.19628245 -0.29043323  0.18617587  0.14708117]\n",
      "ACTIONS: [ 0.16099007  0.5784021  -0.24180616 -0.02190557]\n",
      "ACTIONS: [ 0.37166995 -0.3755601   0.26543388 -0.10323314]\n",
      "ACTIONS: [-0.11478207  0.23697755 -0.28136674 -0.00495759]\n",
      "ACTIONS: [ 0.33916378  0.11421753 -0.3427755   0.8846461 ]\n",
      "ACTIONS: [0.13702801 0.01574574 0.00157456 0.17608286]\n",
      "ACTIONS: [-0.6031077  -0.6891185  -0.02976601  0.28609738]\n",
      "ACTIONS: [ 0.39873162 -0.0701582  -0.35220045  0.07330863]\n",
      "ACTIONS: [-0.05822118  0.13974406 -0.24670288 -0.1098738 ]\n",
      "ACTIONS: [ 0.08690572 -0.9067861   0.24462153  0.02237314]\n",
      "ACTIONS: [ 0.08654582 -0.40093875  0.11793784  0.10525386]\n",
      "ACTIONS: [-0.1677838  -0.31448978 -0.3100038  -0.18537022]\n",
      "ACTIONS: [-0.16769813 -0.13723993 -0.23541653 -0.3561195 ]\n",
      "ACTIONS: [ 0.22812457 -0.27596858  0.4179345   0.76440376]\n",
      "ACTIONS: [ 0.34971756 -0.23992029  0.04224832  0.13222887]\n",
      "ACTIONS: [ 0.18768722 -0.3273243  -0.0463257   0.2441951 ]\n",
      "ACTIONS: [ 0.13990521 -0.37010863 -0.24982257  0.12011455]\n",
      "ACTIONS: [-0.18128483 -0.33034378  0.32490894 -0.35541275]\n",
      "ACTIONS: [ 0.16884814  0.3555302   0.03312385 -0.2616968 ]\n",
      "ACTIONS: [ 0.33884874 -0.0360298  -0.1516967   0.34650853]\n",
      "ACTIONS: [-0.01680483 -0.08175574 -0.0409616   0.2572    ]\n",
      "ACTIONS: [-0.3385696  -0.48538217 -0.0610835  -0.047984  ]\n",
      "ACTIONS: [0.37675494 0.19738682 0.4352237  0.28741178]\n",
      "ACTIONS: [ 0.5641942  -0.6577435  -0.13943557  0.04507483]\n",
      "ACTIONS: [0.19498216 0.24390413 0.11187329 0.27188197]\n",
      "ACTIONS: [ 0.37726358 -0.47100967  0.12335388 -0.12910676]\n",
      "ACTIONS: [-0.27992973 -0.13273963 -0.55539113  0.04554813]\n",
      "ACTIONS: [-0.43711498  0.29843765 -0.3621427  -0.32090107]\n",
      "ACTIONS: [-0.33646095  0.28438497 -0.07166786 -0.1864281 ]\n",
      "ACTIONS: [-0.17079675  0.26686454  0.11652339  0.4309071 ]\n",
      "ACTIONS: [ 0.22706768 -0.2679106  -0.11680066 -0.65070915]\n",
      "ACTIONS: [-0.2618039  -0.34986743  0.04906085  0.40223852]\n",
      "ACTIONS: [ 0.06780311 -0.04629479  0.3597538   0.23808241]\n",
      "ACTIONS: [-0.0307349   0.2965027  -0.09915745  0.00778235]\n",
      "ACTIONS: [-0.06921587 -0.32254666 -0.52644676 -0.18287192]\n",
      "ACTIONS: [ 0.3079257   0.11719385  0.32132795 -0.1868025 ]\n",
      "ACTIONS: [-0.5820961  -0.2208445  -0.21874702 -0.43038008]\n",
      "ACTIONS: [-0.1271359   0.36159697  0.05247606  0.5429327 ]\n",
      "ACTIONS: [ 0.3351504   0.28995764  0.19803412 -0.08786441]\n",
      "ACTIONS: [-0.21349916 -0.27102432  0.37673387 -0.20951855]\n",
      "ACTIONS: [ 0.22203793  0.05026867  0.39089975 -0.3569557 ]\n",
      "ACTIONS: [ 0.23384848 -0.03010467  0.16460328 -0.16859886]\n",
      "ACTIONS: [-0.5558036   0.0395543   0.38841027 -0.2635501 ]\n",
      "ACTIONS: [0.32387164 0.06586589 0.04054075 0.23144428]\n",
      "ACTIONS: [ 0.07308793 -0.41120273  0.587348    0.68347514]\n",
      "ACTIONS: [-0.11869888 -0.11839828 -0.10328354 -0.14059766]\n",
      "ACTIONS: [-0.37004143 -0.2778078   0.17480655 -0.03322445]\n",
      "ACTIONS: [0.39091232 0.05465024 0.1371174  0.18996155]\n",
      "ACTIONS: [ 0.00287282  0.02719186 -0.31679484 -0.05985924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIONS: [-0.19308537 -0.14845064 -0.40432417 -0.4416672 ]\n",
      "ACTIONS: [ 0.1012351  -0.31623068  0.00547595 -0.19404681]\n",
      "ACTIONS: [-0.2970166  -0.18865255 -0.12186845 -0.30413297]\n",
      "ACTIONS: [ 0.40719062 -0.36198708 -0.18326634 -0.30867195]\n",
      "ACTIONS: [-0.23754944 -0.3127232  -0.5600174  -0.10123626]\n",
      "ACTIONS: [-0.3259422  -0.25763902  0.34360456 -0.07229388]\n",
      "ACTIONS: [-0.2848015   0.2072718   0.21084322  0.13098921]\n",
      "ACTIONS: [ 0.5999527  -0.2404937  -0.6527139   0.37243307]\n",
      "ACTIONS: [ 0.29044706  0.03963693 -0.39005908  0.14409314]\n",
      "ACTIONS: [-0.61647457  0.00718306 -0.09980967  0.58261085]\n",
      "ACTIONS: [-0.20516203 -0.07536345  0.01494337  0.08495621]\n",
      "ACTIONS: [-0.01981568  0.17704473 -0.22985974 -0.44495985]\n",
      "ACTIONS: [-0.13787696 -0.21050553 -0.10659299 -0.031178  ]\n",
      "ACTIONS: [ 0.16463126 -0.23933665  0.11565618  0.28922215]\n",
      "ACTIONS: [ 0.07802901 -0.52407855 -0.13504197 -0.5090258 ]\n",
      "ACTIONS: [-0.29265043 -0.42298955 -0.3449492   0.54416215]\n",
      "ACTIONS: [-0.20898987 -0.14429957  0.24299993 -0.60190624]\n",
      "ACTIONS: [-0.03539062  0.14385378 -0.13102512  0.16737087]\n",
      "ACTIONS: [-0.18075672  0.18761957 -0.44548932  0.07738476]\n",
      "ACTIONS: [-0.07916835 -0.06223969  0.4310729   0.1719856 ]\n",
      "ACTIONS: [-0.70851046  0.3597815  -0.00467604  0.27269873]\n",
      "ACTIONS: [ 0.06953944 -0.26298454  0.15012781  0.3764766 ]\n",
      "ACTIONS: [ 0.5456411  -0.85621715 -0.14929447 -0.22546786]\n",
      "ACTIONS: [ 0.05462234 -0.06766194 -0.315823   -0.23484688]\n",
      "ACTIONS: [-0.00341505 -0.07610615 -0.14122036 -0.09580076]\n",
      "ACTIONS: [-0.19149776  0.14341529 -0.25164536  0.41149724]\n",
      "ACTIONS: [-0.26033676  0.21068318 -0.03610243  0.11925326]\n",
      "ACTIONS: [-0.11485713 -0.28350383  0.11431091  0.17168567]\n",
      "ACTIONS: [-0.01236092  0.03446379  0.73869604  0.09306408]\n",
      "ACTIONS: [ 0.15665363 -0.49879032  0.14381604 -0.296399  ]\n",
      "ACTIONS: [0.30222628 0.46053073 0.24858302 0.26563814]\n",
      "ACTIONS: [ 0.46805    -0.13786548 -0.21645243 -0.03406036]\n",
      "ACTIONS: [-0.24179327  0.02470156 -0.44260538 -0.36633068]\n",
      "ACTIONS: [ 0.26998794 -0.5160101  -0.12515736 -0.4378627 ]\n",
      "ACTIONS: [ 0.21976478 -0.08226235  0.3334752  -0.07406174]\n",
      "ACTIONS: [-0.02699632 -0.11213605  0.51103497 -0.00272619]\n",
      "ACTIONS: [ 0.22044796 -0.25558403 -0.18098414 -0.38037035]\n",
      "ACTIONS: [-0.37112865  0.15748496  0.39110506  0.34994742]\n",
      "ACTIONS: [-0.12023014  0.35940868  0.06054145  0.22401576]\n",
      "ACTIONS: [-0.19820657 -0.11397031 -0.29261726 -0.32489926]\n",
      "ACTIONS: [ 0.12558292 -0.6608214  -0.1784902   0.10155964]\n",
      "ACTIONS: [-0.15730001 -0.7480443   0.29907265  0.06752676]\n",
      "ACTIONS: [ 0.19337538 -0.01804016 -0.07225776 -0.0179102 ]\n",
      "ACTIONS: [ 0.09937019  0.4670587  -0.03255556  0.05784579]\n",
      "ACTIONS: [-0.07745738 -0.25085244 -0.03575396  0.11530763]\n",
      "ACTIONS: [-0.33321872 -0.25907204 -0.04239857 -0.17731969]\n",
      "ACTIONS: [ 0.46672752 -0.00807463  0.23462752  0.5667722 ]\n",
      "ACTIONS: [ 0.02854625 -0.19939162 -0.15801562 -0.31146625]\n",
      "ACTIONS: [0.16904308 0.03052315 0.2129804  0.05906524]\n",
      "ACTIONS: [ 0.09682719  0.37468505  0.23068978 -0.46791568]\n",
      "ACTIONS: [-0.20513634  0.02481068 -0.2131604  -0.25667074]\n",
      "ACTIONS: [ 0.03980509 -0.22125496  0.49231791 -0.13599348]\n",
      "ACTIONS: [-0.12223948 -0.03501112 -0.24335991 -0.37323678]\n",
      "ACTIONS: [0.21601062 0.3013227  0.32221714 0.2422848 ]\n",
      "ACTIONS: [ 0.33105302  0.5014165  -0.21920471  0.3030549 ]\n",
      "ACTIONS: [-0.12979455 -0.26682112  0.40005344 -0.04206098]\n",
      "ACTIONS: [ 0.40097502 -0.6536947   0.25569165 -0.03440954]\n",
      "ACTIONS: [ 0.2606492   0.06914192 -0.13295735 -0.22647895]\n",
      "ACTIONS: [-0.16708706  0.10589762 -0.38537347 -0.62062097]\n",
      "ACTIONS: [ 0.24883352 -0.2854471   0.23209336 -0.18220735]\n",
      "ACTIONS: [0.18531752 0.1405809  0.14034995 0.4333684 ]\n",
      "ACTIONS: [ 0.2917533  -0.14844325 -0.03170482  0.33332047]\n",
      "ACTIONS: [-0.29459035 -0.12418007 -0.18309948 -0.5311579 ]\n",
      "ACTIONS: [ 0.25175548  0.11621442 -0.2672519   0.3876999 ]\n",
      "ACTIONS: [0.07039019 0.04305758 0.32508677 0.3939119 ]\n",
      "ACTIONS: [0.3032262  0.06680118 0.17925589 0.4877089 ]\n",
      "ACTIONS: [-0.35186183  0.44549388 -0.5006295  -0.19144003]\n",
      "ACTIONS: [-0.17691745  0.2178276  -0.22990774 -0.01802457]\n",
      "ACTIONS: [-0.2966395   0.48247606 -0.3549839  -0.328011  ]\n",
      "ACTIONS: [-0.2905987  -0.12538728 -0.2688496   0.4409291 ]\n",
      "ACTIONS: [-0.72368515  0.49027938 -0.16328584 -0.54535675]\n",
      "ACTIONS: [-0.10429411 -0.06471924  0.10896499  0.5148811 ]\n",
      "ACTIONS: [ 0.177107    0.16323103 -0.21788675  0.07358457]\n",
      "ACTIONS: [ 0.3288256   0.24308378 -0.21848665 -0.24024883]\n",
      "ACTIONS: [ 0.23202316 -0.10230517  0.01737489  0.08074605]\n",
      "ACTIONS: [-0.10382812  0.17490308  0.25018764  0.19841012]\n",
      "ACTIONS: [ 0.24061166  0.17234486  0.1359535  -0.50931185]\n",
      "ACTIONS: [-0.3568521  -0.33083025 -0.32349452 -0.0144492 ]\n",
      "ACTIONS: [ 0.11041041 -0.15519442 -0.29376608  0.28753585]\n",
      "ACTIONS: [ 0.34362116  0.0881452   0.18840177 -0.23154098]\n",
      "ACTIONS: [-0.28969136  0.37419003 -0.02080509  0.57595336]\n",
      "ACTIONS: [-0.39393175 -0.12422549 -0.52193654 -0.24504676]\n",
      "ACTIONS: [ 0.7691415  -0.04752381  0.09496696  0.20339872]\n",
      "ACTIONS: [ 0.2648017   0.29148263  0.5738116  -0.06491313]\n",
      "ACTIONS: [ 0.4848829   0.4240856   0.41030928 -0.4961044 ]\n",
      "ACTIONS: [-0.42506728 -0.05685405  0.40545344  0.153863  ]\n",
      "ACTIONS: [-0.30838856 -0.05031285  0.08115368  0.11060416]\n",
      "ACTIONS: [-0.11841866  0.2647306   0.01966823 -0.00755777]\n",
      "ACTIONS: [-1.          0.07798137 -0.23270696  0.23380303]\n",
      "ACTIONS: [-0.25743347  0.07651289 -0.40646878  0.26012057]\n",
      "ACTIONS: [ 0.2565387  -0.08507421  0.06316472 -0.01862162]\n",
      "ACTIONS: [ 0.34010756 -0.02002699 -0.32201132 -0.28048554]\n",
      "ACTIONS: [ 0.417269   -0.41584173 -0.02681993  0.20743856]\n",
      "ACTIONS: [ 0.32970756  0.01180344  0.3358895  -0.0408136 ]\n",
      "ACTIONS: [0.27389267 0.45495808 0.02625098 0.16251071]\n",
      "ACTIONS: [ 0.02437342 -0.16253941  0.41739827 -0.17473163]\n",
      "ACTIONS: [ 0.25458488 -0.19911581  0.7386966   0.14540048]\n",
      "ACTIONS: [-0.292565   -0.55793166 -0.3589961   0.20212658]\n",
      "ACTIONS: [-0.1655347  -0.28587732 -0.5751646  -0.20749155]\n",
      "ACTIONS: [ 0.19306733 -0.1906505   0.05902038 -0.47734478]\n",
      "ACTIONS: [ 0.18533686  0.16088808 -0.42014444 -0.44667292]\n",
      "ACTIONS: [-0.11000552 -0.10024352 -0.3210139   0.00115874]\n",
      "ACTIONS: [-0.18216927  0.1183412   0.08858844  0.21637501]\n",
      "ACTIONS: [-0.12018777  0.6861678  -0.13699356 -0.18908237]\n",
      "ACTIONS: [-0.18145882 -0.29234686 -0.2780028   0.30006737]\n",
      "ACTIONS: [ 0.13570596 -0.18393     0.34678483 -0.8767341 ]\n",
      "ACTIONS: [ 0.3640279  -0.56874514 -0.18446313 -0.15567645]\n",
      "ACTIONS: [ 0.06333127  0.01291475  0.07206418 -0.28482047]\n",
      "ACTIONS: [ 0.09364253  0.2062771  -0.20394914 -0.01531293]\n",
      "ACTIONS: [ 0.12384502  0.05940792 -0.28667912  0.16974147]\n",
      "ACTIONS: [ 0.60175574  0.02300851 -0.22141595 -0.04771792]\n",
      "ACTIONS: [-0.06616092  0.5714951   0.30314016  0.23225616]\n",
      "ACTIONS: [-0.15725672 -0.3354298  -0.02482574 -0.02616382]\n",
      "ACTIONS: [ 0.3820557   0.38998136 -0.63307375  0.0205385 ]\n",
      "ACTIONS: [ 0.18143597 -0.18347037  0.08475189  0.3696936 ]\n",
      "ACTIONS: [-0.26607332 -0.6748431   0.3047479  -0.08961377]\n",
      "ACTIONS: [ 0.12189981 -0.05453053 -0.13583697 -0.05163096]\n",
      "ACTIONS: [-0.4106306   0.57907665 -0.11114696  0.29810706]\n",
      "ACTIONS: [ 0.07408591  0.23250693 -0.07407413  0.14955793]\n",
      "ACTIONS: [ 0.11859994  0.39179787 -0.08797172 -0.10443723]\n",
      "ACTIONS: [ 0.11748507  0.10669719 -0.1602456   0.12732063]\n",
      "ACTIONS: [-0.18229407 -0.06415012 -0.46005365  0.2378102 ]\n",
      "ACTIONS: [ 0.22217776 -0.12554829 -0.3998621   0.13608174]\n",
      "ACTIONS: [ 0.2159306   0.24637955 -0.37424675 -0.00317833]\n",
      "ACTIONS: [ 0.10492505 -0.27707827  0.2324786   0.08438898]\n",
      "ACTIONS: [-0.24151616 -0.58672315  0.39074975  0.5116971 ]\n",
      "ACTIONS: [1.         0.11566169 0.00847777 0.6175138 ]\n",
      "ACTIONS: [ 0.25269476 -0.15366513  0.9081753  -0.39581272]\n",
      "ACTIONS: [ 0.15652944 -0.41886795  1.         -0.63887745]\n",
      "ACTIONS: [0.2570316  0.18090563 0.25436354 0.12695673]\n",
      "ACTIONS: [ 0.07679246 -0.22895917  0.43537265 -0.24238251]\n",
      "ACTIONS: [ 0.08576085 -0.13417014  0.21168216 -0.14378081]\n",
      "ACTIONS: [ 0.40097722 -0.22743551  0.02828052 -0.35605195]\n",
      "ACTIONS: [-0.15488712 -0.20815259  0.10037664 -0.23394504]\n",
      "ACTIONS: [-0.17435022  0.34891006  0.5054734   0.30242524]\n",
      "ACTIONS: [ 0.0712414   0.1247784  -0.30516493  0.25967118]\n",
      "ACTIONS: [-0.47596288 -0.11076368 -0.31031045 -0.4531579 ]\n",
      "ACTIONS: [ 0.26235726  0.3209477  -0.1260283  -0.01179141]\n",
      "ACTIONS: [-0.14371033 -0.516758    0.23340505 -0.43010202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIONS: [ 0.01999115 -0.07211079  0.05800765 -0.7156198 ]\n",
      "ACTIONS: [-0.1131888  -0.03167914  0.39704704  0.04985125]\n",
      "ACTIONS: [ 0.1707986   0.17535986 -0.18388934  0.18508905]\n",
      "ACTIONS: [ 0.34602582 -0.5155452  -0.3216077  -0.49399054]\n",
      "ACTIONS: [ 0.21240127  0.220057    0.0998925  -0.05200554]\n",
      "ACTIONS: [-0.42082015  0.5404009   0.3127645   0.32569203]\n",
      "ACTIONS: [-0.01972523  0.5407506   0.16946614 -0.04559203]\n",
      "ACTIONS: [ 0.20376284  0.05253517  0.38212094 -0.17802615]\n",
      "ACTIONS: [-0.49493235  0.14781837  0.41671538 -0.36746293]\n",
      "ACTIONS: [ 0.22824979  0.27843413 -0.5000596  -0.571131  ]\n",
      "ACTIONS: [ 0.40300834  0.18392001  0.27293563 -0.38836813]\n",
      "ACTIONS: [ 0.25405303 -0.16768111 -0.22785416 -0.27156442]\n",
      "ACTIONS: [-0.12524925  0.40104526  0.41193968  0.19621332]\n",
      "ACTIONS: [-0.13101798 -0.2090228   0.11435518 -0.13032082]\n",
      "ACTIONS: [ 0.18751849 -0.17107828  0.28036445  0.40508705]\n",
      "ACTIONS: [-0.38494578 -0.21333385 -0.07074345  0.02364682]\n",
      "ACTIONS: [-0.32675585 -0.18471791 -0.04540517  0.31333143]\n",
      "ACTIONS: [-0.00838305 -0.24503477  0.17986609 -0.10867506]\n",
      "ACTIONS: [-0.14000261 -0.0898219  -0.07378695  0.12377168]\n",
      "ACTIONS: [0.24421233 0.7300248  0.02961016 0.38967097]\n",
      "ACTIONS: [ 0.01267026 -0.04570791  0.00305868  0.391046  ]\n",
      "ACTIONS: [0.01960097 0.23725119 0.5978034  0.17553386]\n",
      "Total score (averaged over agents) this episode: 0.026999999396502973\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "scores = np.zeros(env.agent_count)\n",
    "states = env.states\n",
    "for i in range(30):\n",
    "    actions = d4pg_agent.act(states)\n",
    "    print(\"ACTIONS:\", actions[1])\n",
    "    next_states, rewards, dones = env.step(actions)\n",
    "    scores += rewards\n",
    "    states = next_states\n",
    "    if np.any(dones):\n",
    "        break\n",
    "    i += 1\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out Critic scores without training\n",
    "<i> Test the <b>Critic</b> network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "tensor([0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0195, 0.0196,\n",
      "        0.0196, 0.0197, 0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0197, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0197, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0196, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0196, 0.0197, 0.0196, 0.0196, 0.0196],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward>)\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "scores = np.zeros(env.agent_count)\n",
    "states = env.states\n",
    "for i in range(10):\n",
    "    actions = d4pg_agent.act(states) \n",
    "    next_states, rewards, dones = env.step(actions)\n",
    "    scores += rewards\n",
    "    q, probs = d4pg_agent.critic(next_states, torch.from_numpy(actions))\n",
    "    print(probs[0])\n",
    "    print(q[0])\n",
    "    #print(values.sample())\n",
    "    states = next_states\n",
    "    if np.any(dones):\n",
    "        break\n",
    "    i += 1\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn about how the Categorical Bellman step works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.random.randn(env.agent_count, env.action_size)\n",
    "actions = np.clip(actions, -1, 1).astype(np.float32)\n",
    "states = torch.from_numpy(env.states).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, probs, log_probs = critic(states, torch.from_numpy(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs.shape)\n",
    "print(log_probs.shape)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Container():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "c = Container()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.vmin = -10\n",
    "c.vmax = 10\n",
    "c.natoms = 51\n",
    "c.gamma = .99\n",
    "c.atoms = torch.linspace(vmin, vmax, natoms)\n",
    "c.delta_z = (vmax - vmin) / (natoms -1)\n",
    "c.r = torch.tensor(rewards).unsqueeze(-1)\n",
    "\n",
    "c.probs = probs.detach()\n",
    "c.q_next = (probs * atoms).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vars(x):\n",
    "    for arg in vars(x):\n",
    "        print(\"{}: {}\".format(arg.upper(), getattr(x, arg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.0000,  -9.6000,  -9.2000,  -8.8000,  -8.4000,  -8.0000,  -7.6000,\n",
       "         -7.2000,  -6.8000,  -6.4000,  -6.0000,  -5.6000,  -5.2000,  -4.8000,\n",
       "         -4.4000,  -4.0000,  -3.6000,  -3.2000,  -2.8000,  -2.4000,  -2.0000,\n",
       "         -1.6000,  -1.2000,  -0.8000,  -0.4000,   0.0000,   0.4000,   0.8000,\n",
       "          1.2000,   1.6000,   2.0000,   2.4000,   2.8000,   3.2000,   3.6000,\n",
       "          4.0000,   4.4000,   4.8000,   5.2000,   5.6000,   6.0000,   6.4000,\n",
       "          6.8000,   7.2000,   7.6000,   8.0000,   8.4000,   8.8000,   9.2000,\n",
       "          9.6000,  10.0000])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### projected atoms\n",
    "<html><i>\n",
    "<b>atoms.view(1,-1)</b> becomes shape [1, num_atoms]\n",
    "<br>\n",
    "<b>r</b> is unsqueezed in the last (-1) dimension, so it's shape [20,1]\n",
    "<br>\n",
    "the result is a tensor that holds an offset (projected) version of the atoms for each reward instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tz = projected atoms, atoms (values) projected by scaling and offsetting via the bellman equation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.9000, -9.5040, -9.1080,  ...,  9.1080,  9.5040,  9.9000],\n",
       "        [-9.9000, -9.5040, -9.1080,  ...,  9.1080,  9.5040,  9.9000],\n",
       "        [-9.9000, -9.5040, -9.1080,  ...,  9.1080,  9.5040,  9.9000],\n",
       "        ...,\n",
       "        [-9.9000, -9.5040, -9.1080,  ...,  9.1080,  9.5040,  9.9000],\n",
       "        [-9.9000, -9.5040, -9.1080,  ...,  9.1080,  9.5040,  9.9000],\n",
       "        [-9.9000, -9.5040, -9.1080,  ...,  9.1080,  9.5040,  9.9000]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz = c.r + c.gamma * c.atoms.view(1,-1)\n",
    "tz.clamp_(vmin, vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### computes \"bj\" from the pseudo-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25000095,  1.2399983 ,  2.2300005 ,  3.2200003 ,  4.21      ,\n",
       "        5.2       ,  6.1899996 ,  7.1800003 ,  8.169999  ,  9.160001  ,\n",
       "       10.15      , 11.139999  , 12.13      , 13.12      , 14.11      ,\n",
       "       15.099999  , 16.09      , 17.08      , 18.07      , 19.06      ,\n",
       "       20.050001  , 21.04      , 22.03      , 23.02      , 24.01      ,\n",
       "       25.        , 25.990002  , 26.98      , 27.97      , 28.960001  ,\n",
       "       29.949999  , 30.94      , 31.93      , 32.92      , 33.91      ,\n",
       "       34.899998  , 35.890003  , 36.88      , 37.87      , 38.86      ,\n",
       "       39.850002  , 40.839996  , 41.830006  , 42.82      , 43.81      ,\n",
       "       44.8       , 45.79      , 46.780003  , 47.770004  , 48.760002  ,\n",
       "       49.75      ], dtype=float32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = (tz - c.vmin) / c.delta_z\n",
    "b[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### l/u in the psuedocode are LOWER and UPPER bounds on the supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
      "        35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])\n"
     ]
    }
   ],
   "source": [
    "l = b.floor().long()\n",
    "u = b.ceil().long()\n",
    "print(l[0])\n",
    "print(u[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### m_l/m_u are computed in the pseudocode under \"distribute the probability of tz\", but still a bit opaque to me on how it should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01467833, 0.01493664, 0.01510203, 0.0153105 , 0.01546834,\n",
       "       0.01571159, 0.01590588, 0.0160307 , 0.01628518, 0.01649079,\n",
       "       0.01670613, 0.01687601, 0.01705097, 0.01730292, 0.01742529,\n",
       "       0.01766971, 0.01783578, 0.0180223 , 0.01823092, 0.01840046,\n",
       "       0.0186618 , 0.01879957, 0.01903829, 0.01920612, 0.0193745 ,\n",
       "       0.01964528, 0.00019637, 0.00039313, 0.00058676, 0.00078374,\n",
       "       0.00098073, 0.00117412, 0.00136963, 0.00156546, 0.00176948,\n",
       "       0.00196226, 0.00215623, 0.00235884, 0.00255588, 0.0027378 ,\n",
       "       0.00293237, 0.00312979, 0.00333509, 0.00352029, 0.00372426,\n",
       "       0.00392292, 0.00411897, 0.00432351, 0.00451106, 0.00469343,\n",
       "       0.0049065 ], dtype=float32)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version from GITHUB implementations\n",
    "\n",
    "gdml = (u.float() + (l == u).float() - b) * c.probs\n",
    "gdml[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0048928 , 0.00471679, 0.00451101, 0.00431835, 0.00411184,\n",
       "       0.00392789, 0.003731  , 0.00351894, 0.0033355 , 0.00314112,\n",
       "       0.00294813, 0.00274724, 0.00254785, 0.00235949, 0.00215368,\n",
       "       0.00196329, 0.00176398, 0.00156716, 0.00137221, 0.00117449,\n",
       "       0.00098222, 0.00078333, 0.00058883, 0.00039197, 0.00019571,\n",
       "       0.        , 0.01944361, 0.01926299, 0.01897159, 0.01881013,\n",
       "       0.01863343, 0.01839465, 0.01819655, 0.01800233, 0.01789142,\n",
       "       0.01765985, 0.01744645, 0.01729832, 0.0171046 , 0.01681799,\n",
       "       0.01661707, 0.01643098, 0.01628374, 0.01603686, 0.01587726,\n",
       "       0.01569162, 0.01549527, 0.01532905, 0.01510262, 0.01486269,\n",
       "       0.01471951], dtype=float32)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version from GITHUB implementations\n",
    "\n",
    "gdmu = (b - l.float()) * c.probs\n",
    "gdmu[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01467833,  1.0149367 ,  2.0151021 ,  3.0153105 ,  4.015468  ,\n",
       "        5.015712  ,  6.015906  ,  7.016031  ,  8.016285  ,  9.016491  ,\n",
       "       10.016706  , 11.016876  , 12.017051  , 13.0173025 , 14.017426  ,\n",
       "       15.01767   , 16.017836  , 17.018023  , 18.01823   , 19.0184    ,\n",
       "       20.018661  , 21.018799  , 22.01904   , 23.019207  , 24.019375  ,\n",
       "       25.        , 25.000196  , 26.000393  , 27.000587  , 28.000784  ,\n",
       "       29.00098   , 30.001175  , 31.00137   , 32.001564  , 33.00177   ,\n",
       "       34.00196   , 35.002155  , 36.002357  , 37.002556  , 38.00274   ,\n",
       "       39.002934  , 40.003128  , 41.003334  , 42.00352   , 43.003723  ,\n",
       "       44.00392   , 45.00412   , 46.004322  , 47.004513  , 48.004692  ,\n",
       "       49.004906  ], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version from the PAPER\n",
    "\n",
    "pdml = l.float() + (c.probs * (u.float()-b))\n",
    "pdml[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0048928,  2.0047169,  3.004511 ,  4.004318 ,  5.004112 ,\n",
       "        6.0039277,  7.003731 ,  8.003519 ,  9.003336 , 10.003141 ,\n",
       "       11.002948 , 12.002748 , 13.002548 , 14.002359 , 15.002153 ,\n",
       "       16.001963 , 17.001764 , 18.001568 , 19.001371 , 20.001175 ,\n",
       "       21.000982 , 22.000784 , 23.00059  , 24.000393 , 25.000196 ,\n",
       "       25.       , 26.019444 , 27.019262 , 28.018972 , 29.01881  ,\n",
       "       30.018633 , 31.018394 , 32.018196 , 33.018    , 34.01789  ,\n",
       "       35.01766  , 36.017445 , 37.0173   , 38.017105 , 39.01682  ,\n",
       "       40.016617 , 41.01643  , 42.016285 , 43.016037 , 44.015877 ,\n",
       "       45.01569  , 46.015495 , 47.015327 , 48.015102 , 49.014862 ,\n",
       "       50.01472  ], dtype=float32)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version from the PAPER\n",
    "\n",
    "pdmu = u.float() + (c.probs * (b - l.float()))\n",
    "pdmu[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_prob.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01467833, 0.01982944, 0.01981882, 0.01982151, 0.01978669,\n",
       "       0.01982343, 0.01983377, 0.0197617 , 0.01980412, 0.01982629,\n",
       "       0.01984725, 0.01982415, 0.01979821, 0.01985077, 0.01978477,\n",
       "       0.01982339, 0.01979907, 0.01978629, 0.01979808, 0.01977267,\n",
       "       0.01983629, 0.0197818 , 0.01982162, 0.01979494, 0.01976647,\n",
       "       0.02003736, 0.01983674, 0.01984975, 0.01975532, 0.01979086,\n",
       "       0.01980755, 0.01976428, 0.01976201, 0.01977182, 0.01985367,\n",
       "       0.01981608, 0.01980529, 0.01985421, 0.0198424 , 0.01975036,\n",
       "       0.01974687, 0.01976607, 0.01980403, 0.01976112, 0.01980018,\n",
       "       0.01981059, 0.01981879, 0.01984012, 0.01979605, 0.0197692 ,\n",
       "       0.01471951])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_prob = torch.tensor(np.zeros(probs.size()))\n",
    "for i in range(target_prob.size(0)):\n",
    "    target_prob[i].index_add_(0, l[i].long(), gdml[i].double())\n",
    "    target_prob[i].index_add_(0, u[i].long(), gdmu[i].double())\n",
    "target_prob[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip dml and dmu together offset by 1 index and subtract 1, receive amount to add to probs!\n",
    "x = zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01957113, 0.01965343, 0.01961304, 0.01962886, 0.01958018,\n",
       "       0.01963948, 0.01963687, 0.01954965, 0.01962068, 0.01963191,\n",
       "       0.01965426, 0.01962326, 0.01959882, 0.0196624 , 0.01957897,\n",
       "       0.019633  , 0.01959976, 0.01958946, 0.01960313, 0.01957494,\n",
       "       0.01964402, 0.01958291, 0.01962711, 0.01959809, 0.01957021,\n",
       "       0.01964528, 0.01963998, 0.01965612, 0.01955835, 0.01959387,\n",
       "       0.01961417, 0.01956877, 0.01956618, 0.01956779, 0.0196609 ,\n",
       "       0.0196221 , 0.01960268, 0.01965716, 0.01966049, 0.01955579,\n",
       "       0.01954945, 0.01956077, 0.01961883, 0.01955715, 0.01960152,\n",
       "       0.01961454, 0.01961425, 0.01965257, 0.01961369, 0.01955612,\n",
       "       0.01962601], dtype=float32)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.probs[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
