{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><b><font size=10> CONTINUOUS CONTROL</font></b>\n",
    "#### <i>...implementation for Udacity Deep Reinforcement Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Imports for the notebook\n",
    "This Notebook uses code from separate python files where most of the implementation is handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import env as E\n",
    "from buffers import ReplayBuffer, nStepBuffer\n",
    "from agent import D4PG_Agent\n",
    "\n",
    "# from agent import Agent\n",
    "#from get_args import get_args\n",
    "\n",
    "import os.path\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from unityagents import UnityEnvironment\n",
    "from collections import deque\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing as multi\n",
    "multi.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually declare an ARGS class for the notebook, to take the place of argparser in the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.train = True\n",
    "        self.nographics = False\n",
    "        self.num_eps = 10\n",
    "        self.rollout = 5\n",
    "        self.batchsize = 64\n",
    "        \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the args are all set the way we want them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: True\n",
      "NOGRAPHICS: False\n",
      "NUM_EPS: 10\n",
      "ROLLOUT: 5\n",
      "BATCHSIZE: 64\n"
     ]
    }
   ],
   "source": [
    "for arg in vars(args):\n",
    "    if arg == \"sep\": continue\n",
    "    print(\"{}: {}\".format(arg.upper(), getattr(args, arg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the environment and print a bit of information contained in the wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 33\n",
      "Action size: 4\n",
      "Num Agents: 20\n"
     ]
    }
   ],
   "source": [
    "env = E.Environment(args)\n",
    "print(\"State size:\", env.state_size)\n",
    "print(\"Action size:\", env.action_size)\n",
    "print(\"Num Agents:\", env.agent_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.train = False\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D4PG_Agent\n",
      "<buffers.ReplayBuffer object at 0x0000022B157890B8>\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import agent\n",
    "import buffers\n",
    "importlib.reload(agent)\n",
    "importlib.reload(buffers)\n",
    "\n",
    "agent = agent.D4PG_Agent(env.state_size, env.action_size, env.agent_count, args.rollout)\n",
    "print(agent.__class__.__name__)\n",
    "print(agent.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.initialize_memory(10, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 3.04229736e-01, -3.85277534e+00,  1.04340935e+00,  9.90642488e-01,\n",
       "          3.75220217e-02, -5.08871023e-03,  1.31124720e-01, -1.54979753e+00,\n",
       "         -1.84099838e-01, -7.77908623e-01, -3.20201230e+00,  1.14378190e+00,\n",
       "          6.10855913e+00,  3.14542770e+00, -8.11408138e+00,  1.27618027e+00,\n",
       "          8.50841761e-01,  5.01510382e-01,  6.24258779e-02, -1.43731460e-01,\n",
       "          3.01464391e+00,  1.61010101e-01, -6.19705200e-01, -6.95457935e+00,\n",
       "          1.61413252e+00,  3.92670584e+00, -7.06779480e-01, -1.00000000e+00,\n",
       "         -7.96871758e+00,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          2.48647571e-01]),\n",
       "  array([ 7.26966858e-02, -3.76719809e+00,  1.34849930e+00,  9.85368788e-01,\n",
       "          8.90237559e-03, -1.58634002e-03,  1.70196012e-01, -6.98284984e-01,\n",
       "         -2.23298222e-01, -6.55851781e-01, -2.78443551e+00,  8.20453823e-01,\n",
       "          2.68524647e+00,  2.70648193e+00, -7.99369860e+00,  1.73191643e+00,\n",
       "          8.51840556e-01,  4.86774176e-01,  8.81215110e-02, -1.72201023e-01,\n",
       "          1.32495776e-01, -3.98786426e-01, -1.82541117e-01, -4.86046648e+00,\n",
       "          8.59208822e-01,  5.94246864e+00, -8.44989777e-01, -1.00000000e+00,\n",
       "         -7.95524979e+00,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          2.48647571e-01]),\n",
       "  array([-1.52271271e-01, -3.70260668e+00,  1.51129341e+00,  9.81291294e-01,\n",
       "         -1.85954552e-02,  3.59771075e-03,  1.91595197e-01, -4.58438933e-01,\n",
       "         -2.61155128e-01, -6.60567582e-01, -2.85510969e+00,  7.40488887e-01,\n",
       "          1.68871570e+00,  2.33593369e+00, -7.87367249e+00,  2.10122299e+00,\n",
       "          8.47509325e-01,  4.87537265e-01,  1.17895491e-01, -1.73597291e-01,\n",
       "          3.30776602e-01, -6.11689091e-01,  1.00860029e-01, -4.26644802e+00,\n",
       "          1.95656824e+00,  4.61497974e+00, -9.82948303e-01, -1.00000000e+00,\n",
       "         -7.93938351e+00,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          2.48647571e-01]),\n",
       "  array([-0.40291595, -3.6237731 ,  1.65140915,  0.97622198, -0.04904763,\n",
       "          0.01055133,  0.21088798, -0.52040631, -0.3347328 , -0.75953186,\n",
       "         -3.32556558,  1.09652221,  1.79532063,  1.92333221, -7.69356298,\n",
       "          2.36081696,  0.83497483,  0.48424447,  0.16693251, -0.20114157,\n",
       "          1.84536529, -0.81254756, -0.12173612, -5.43124533,  2.85290337,\n",
       "          2.56416392, -1.12060928, -1.        , -7.92112541,  0.        ,\n",
       "          1.        ,  0.        ,  0.24864757]),\n",
       "  array([-0.66796875, -3.58080769,  1.6591835 ,  0.97338539, -0.08142117,\n",
       "          0.01787185,  0.21347639,  0.18067153, -0.34535882, -0.74241912,\n",
       "         -3.25481558,  0.14501598, -0.85953474,  1.50610352, -7.59898233,\n",
       "          2.57694817,  0.83010375,  0.49877566,  0.18002456, -0.17245844,\n",
       "         -1.64342201, -0.75593787,  0.27465105, -4.68542957,  0.35129416,\n",
       "          4.73358488, -1.25793076, -1.        , -7.90048122,  0.        ,\n",
       "          1.        ,  0.        ,  0.24864757])),\n",
       " (array([-1.54359627e+00, -3.69306898e+00, -4.18690667e-02,  9.80634868e-01,\n",
       "         -1.95765510e-01, -1.03404920e-03, -5.49001480e-03,  1.30145037e+00,\n",
       "         -7.10631628e-03, -4.71292526e-01, -1.75686908e+00,  6.38555229e-01,\n",
       "         -4.86113405e+00, -2.17325211e-01, -7.58479214e+00, -1.34083414e+00,\n",
       "          6.81383073e-01,  2.64734983e-01,  4.71889228e-01, -4.92902786e-01,\n",
       "          2.32033658e+00, -1.52159739e+00, -3.35427970e-01, -7.36270189e-01,\n",
       "          4.33491802e+00, -6.96804810e+00, -7.97724342e+00, -1.00000000e+00,\n",
       "         -6.02984071e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         -7.01052189e-01]),\n",
       "  array([-1.6674366 , -3.62065911, -0.36318961,  0.9760161 , -0.2119592 ,\n",
       "         -0.01050007, -0.04853522,  0.97101313,  0.03218042, -0.40324509,\n",
       "         -1.48542809,  0.94455379, -3.50152779, -0.32628822, -7.21561527,\n",
       "         -1.88041699,  0.58312958,  0.21165916,  0.55350548, -0.55569065,\n",
       "          4.02795744, -1.43397987, -0.52730304, -0.691953  ,  7.07756472,\n",
       "         -6.34917021, -7.93819046, -1.        , -0.99253291,  0.        ,\n",
       "          1.        ,  0.        , -0.70105219]),\n",
       "  array([-1.76326752, -3.53036165, -0.67374694,  0.97006142, -0.22409867,\n",
       "         -0.02103521, -0.09120435,  1.15237617,  0.04777512, -0.28865796,\n",
       "         -1.06021821,  1.18518436, -4.03642988, -0.39183998, -6.73269176,\n",
       "         -2.39476061,  0.45357853,  0.1308881 ,  0.62181008, -0.62488967,\n",
       "          4.40822077, -1.26978505, -0.42450663,  0.06459063,  8.43954086,\n",
       "         -6.20848894, -7.88012695, -1.        , -1.37970483,  0.        ,\n",
       "          1.        ,  0.        , -0.70105219]),\n",
       "  array([-1.78716850e+00, -3.44724202e+00, -9.74598825e-01,  9.64463532e-01,\n",
       "         -2.26175219e-01, -3.11871804e-02, -1.32974401e-01,  9.90253031e-01,\n",
       "         -6.80853100e-03,  2.62241121e-02,  9.75501761e-02,  8.49087894e-01,\n",
       "         -3.46315598e+00, -3.94826889e-01, -6.29254818e+00, -2.93107343e+00,\n",
       "          3.71552587e-01,  7.11575896e-02,  6.36280000e-01, -6.72334075e-01,\n",
       "          1.96501374e+00,  6.29783571e-02,  4.06228483e-01,  2.54626185e-01,\n",
       "          6.66641760e+00, -7.25686216e+00, -7.80319214e+00, -1.00000000e+00,\n",
       "         -1.76357234e+00,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         -7.01052189e-01]),\n",
       "  array([-1.72379494, -3.40120053, -1.21988261,  0.96127772, -0.2165511 ,\n",
       "         -0.03748254, -0.16627067,  0.7680319 , -0.10266761,  0.30251169,\n",
       "          1.15673125,  0.3650336 , -2.81288147, -0.32826233, -5.98824549,\n",
       "         -3.47644854,  0.36490813,  0.0516446 ,  0.61035967, -0.70116764,\n",
       "         -0.01923947,  0.70759445,  0.90843731,  0.75659364,  4.24104118,\n",
       "         -7.7454381 , -7.70756912, -1.        , -2.14321637,  0.        ,\n",
       "          1.        ,  0.        , -0.70105219])))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory.sample(2).states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'reward'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-93374d818fc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmemory\u001b[0m \u001b[1;32min\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'reward'"
     ]
    }
   ],
   "source": [
    "for memory in agent.memory.sample(2):\n",
    "    print(memory.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take random actions in the environment below \n",
    "<i>\n",
    "-to check that code is working<br>\n",
    "-to get familiar with the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros(env.agent_count)\n",
    "states = env.states\n",
    "for i in range(200):\n",
    "    actions = np.random.randn(env.agent_count, env.action_size)\n",
    "    actions = np.clip(actions, -1, 1)\n",
    "    rewards, dones = env.step(actions)\n",
    "    scores += rewards\n",
    "    states = env.states\n",
    "    if np.any(dones):\n",
    "        break\n",
    "    i += 1\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.random.rand(env.agent_count, env.action_size) * 2 - 1\n",
    "next_states = env.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actions.shape)\n",
    "#print(actions)\n",
    "print(states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = namedtuple(\"test\", field_names=['state','action','reward','next_state'])\n",
    "a = deque(maxlen=5)\n",
    "#a.maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = zip(states, actions, rewards, next_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(states, actions, rewards, next_states))\n",
    "b = []\n",
    "for i in c:\n",
    "    #print(x(list(i)))\n",
    "    #print(list(i))\n",
    "    print(x(i[0],i[1],i[2],i[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape [20, 4]\n",
    "agents = [x(*i) for i in zip(states, actions, rewards, next_states)]\n",
    "len(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    a.append(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memories = [agent for agent in zip(*a)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memories[0][0].state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = env.states\n",
    "actions = np.random.rand(20, 4) * 2 - 1\n",
    "# [20,1], [20,1]\n",
    "rewards, done = env.step(actions)\n",
    "# [20, 33]\n",
    "next_states = env.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((20,4))\n",
    "\n",
    "for r in range(x.shape[0]):\n",
    "    x[r][0] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "for i in range(10):\n",
    "    env.step(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env2 = env\n",
    "for i in range(100):\n",
    "    env2.step(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    env.step(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
